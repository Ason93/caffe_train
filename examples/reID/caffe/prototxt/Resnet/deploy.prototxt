name: "ResNet"
input: "data"
input_dim: 1
input_dim: 3
input_dim: 384
input_dim: 128


layer {
  bottom: "data"
    top: "conv1"
    name: "conv1"
    type: "Convolution"
    convolution_param {
    num_output: 64
      kernel_size: 5
      pad: 2
      stride: 2
	  weight_filler { type: "msra" std: 0.010 }
	  bias_filler { type: "constant" value: 0 }
      }
}

layer {
  bottom: "conv1"
    top: "conv1"
    name: "bn_conv1"
    type: "BatchNorm"
    
    param { lr_mult: 0 }
    param { lr_mult: 0 }
    param { lr_mult: 0 }
}

layer {
  bottom: "conv1"
    top: "conv1"
    name: "scale_conv1"
    type: "Scale"
    scale_param {
    bias_term: true
      }
	param { lr_mult: 0 }
}

layer {
  bottom: "conv1"
    top: "conv1"
    name: "conv1_relu"
    type: "ReLU"
    }

layer {
  bottom: "conv1"
    top: "pool1"
    name: "pool1"
    type: "Pooling"
    pooling_param {
    kernel_size: 3
      stride: 2
      pool: MAX
      }
}
##########################
######first shortcut######
##########################
layer {
  bottom: "pool1"
    top: "res2a_branch1"
    name: "res2a_branch1"
    type: "Convolution"
    convolution_param {
    num_output: 64
      kernel_size: 1
      pad: 0
      stride: 1
      bias_term: false
	  weight_filler { type: "msra" std: 0.010 }
      }
}

layer {
  bottom: "res2a_branch1"
    top: "res2a_branch1"
    name: "bn2a_branch1"
    type: "BatchNorm"
    
	param { lr_mult: 0 }
    param { lr_mult: 0 }
    param { lr_mult: 0 }
}

layer {
  bottom: "res2a_branch1"
    top: "res2a_branch1"
    name: "scale2a_branch1"
    type: "Scale"
    scale_param {
    bias_term: true
      }
	param { lr_mult: 0 }
}

layer {
  bottom: "pool1"
    top: "res2a_branch2a"
    name: "res2a_branch2a"
    type: "Convolution"
    convolution_param {
    num_output: 32
      kernel_size: 3
      pad: 1
      stride: 1
      bias_term: false
	  weight_filler { type: "msra" std: 0.010 }
      }
}

layer {
  bottom: "res2a_branch2a"
    top: "res2a_branch2a"
    name: "bn2a_branch2a"
    type: "BatchNorm"
    
	param { lr_mult: 0 }
    param { lr_mult: 0 }
    param { lr_mult: 0 }
}

layer {
  bottom: "res2a_branch2a"
    top: "res2a_branch2a"
    name: "scale2a_branch2a"
    type: "Scale"
    scale_param {
    bias_term: true
      }
	param { lr_mult: 0 }
}

layer {
  bottom: "res2a_branch2a"
    top: "res2a_branch2a"
    name: "res2a_branch2a_relu"
    type: "ReLU"
    }

layer {
  bottom: "res2a_branch2a"
    top: "res2a_branch2b"
    name: "res2a_branch2b"
    type: "Convolution"
    convolution_param {
    num_output: 64
      kernel_size: 3
      pad: 1
      stride: 1
      bias_term: false
	  weight_filler { type: "msra" std: 0.010 }
      }
}

layer {
  bottom: "res2a_branch2b"
    top: "res2a_branch2b"
    name: "bn2a_branch2b"
    type: "BatchNorm"
    
	param { lr_mult: 0 }
    param { lr_mult: 0 }
    param { lr_mult: 0 }
}

layer {
  bottom: "res2a_branch2b"
    top: "res2a_branch2b"
    name: "scale2a_branch2b"
    type: "Scale"
    scale_param {
    bias_term: true
      }
	param { lr_mult: 0 }
}

layer {
    bottom: "res2a_branch1"
    bottom: "res2a_branch2b"
    top: "res2a"
    name: "res2a"
    type: "Eltwise"
    }

layer {
  bottom: "res2a"
    top: "res2a"
    name: "res2a_relu"
    type: "ReLU"
    }

layer {
    bottom: "res2a"
    top: "res2b_branch2a"
    name: "res2b_branch2a"
    type: "Convolution"
    convolution_param {
    num_output: 32
      kernel_size: 3
      pad: 1
      stride: 1
      bias_term: false
	  weight_filler { type: "msra" std: 0.010 }
      }
}

layer {
  bottom: "res2b_branch2a"
    top: "res2b_branch2a"
    name: "bn2b_branch2a"
    type: "BatchNorm"
    
	param { lr_mult: 0 }
    param { lr_mult: 0 }
    param { lr_mult: 0 }
}

layer {
  bottom: "res2b_branch2a"
    top: "res2b_branch2a"
    name: "scale2b_branch2a"
    type: "Scale"
    scale_param {
    bias_term: true
      }
	param { lr_mult: 0 }
}

layer {
  bottom: "res2b_branch2a"
    top: "res2b_branch2a"
    name: "res2b_branch2a_relu"
    type: "ReLU"
    }

layer {
  bottom: "res2b_branch2a"
    top: "res2b_branch2b"
    name: "res2b_branch2b"
    type: "Convolution"
    convolution_param {
    num_output: 64
      kernel_size: 3
      pad: 1
      stride: 1
      bias_term: false
	  weight_filler { type: "msra" std: 0.010 }
      }
}

layer {
  bottom: "res2b_branch2b"
    top: "res2b_branch2b"
    name: "bn2b_branch2b"
    type: "BatchNorm"
    
	param { lr_mult: 0 }
    param { lr_mult: 0 }
    param { lr_mult: 0 }
}

layer {
  bottom: "res2b_branch2b"
    top: "res2b_branch2b"
    name: "scale2b_branch2b"
    type: "Scale"
    scale_param {
    bias_term: true
      }
	param { lr_mult: 0 }
}

layer {
  bottom: "res2a"
    bottom: "res2b_branch2b"
    top: "res2b"
    name: "res2b"
    type: "Eltwise"
    }

layer {
  bottom: "res2b"
    top: "res2b"
    name: "res2b_relu"
    type: "ReLU"
    }


##########################
######second shortcut#####
##########################

layer {
  bottom: "res2b"
    top: "res3a_branch1"
    name: "res3a_branch1"
    type: "Convolution"
    convolution_param {
    num_output: 64
      kernel_size: 1
      pad: 0
      stride: 2
      bias_term: false
	  weight_filler { type: "msra" std: 0.010 }
      }
}

layer {
  bottom: "res3a_branch1"
    top: "res3a_branch1"
    name: "bn3a_branch1"
    type: "BatchNorm"
    
	param { lr_mult: 0 }
    param { lr_mult: 0 }
    param { lr_mult: 0 }
}

layer {
  bottom: "res3a_branch1"
    top: "res3a_branch1"
    name: "scale3a_branch1"
    type: "Scale"
    scale_param {
    bias_term: true
      }
	param { lr_mult: 0 }
}

layer {
  bottom: "res2b"
    top: "res3a_branch2a"
    name: "res3a_branch2a"
    type: "Convolution"
    convolution_param {
    num_output: 32
      kernel_size: 3
      pad: 1
      stride: 2
      bias_term: false
	  weight_filler { type: "msra" std: 0.010 }
      }
}

layer {
  bottom: "res3a_branch2a"
    top: "res3a_branch2a"
    name: "bn3a_branch2a"
    type: "BatchNorm"
    
	param { lr_mult: 0 }
    param { lr_mult: 0 }
    param { lr_mult: 0 }
}

layer {
  bottom: "res3a_branch2a"
    top: "res3a_branch2a"
    name: "scale3a_branch2a"
    type: "Scale"
    scale_param {
    bias_term: true
      }
	param { lr_mult: 0 }
}

layer {
  bottom: "res3a_branch2a"
    top: "res3a_branch2a"
    name: "res3a_branch2a_relu"
    type: "ReLU"
    }

layer {
  bottom: "res3a_branch2a"
    top: "res3a_branch2b"
    name: "res3a_branch2b"
    type: "Convolution"
    convolution_param {
    num_output: 64
      kernel_size: 3
      pad: 1
      stride: 1
      bias_term: false
	  weight_filler { type: "msra" std: 0.010 }
      }
}

layer {
  bottom: "res3a_branch2b"
    top: "res3a_branch2b"
    name: "bn3a_branch2b"
    type: "BatchNorm"
    
	param { lr_mult: 0 }
    param { lr_mult: 0 }
    param { lr_mult: 0 }
}

layer {
  bottom: "res3a_branch2b"
    top: "res3a_branch2b"
    name: "scale3a_branch2b"
    type: "Scale"
    scale_param {
    bias_term: true
      }
	param { lr_mult: 0 }
}

layer {
  bottom: "res3a_branch1"
    bottom: "res3a_branch2b"
    top: "res3a"
    name: "res3a"
    type: "Eltwise"
    }

layer {
  bottom: "res3a"
    top: "res3a"
    name: "res3a_relu"
    type: "ReLU"
    }


layer {
  bottom: "res3a"
    top: "res3b_branch2a"
    name: "res3b_branch2a"
    type: "Convolution"
    convolution_param {
    num_output: 64
      kernel_size: 3
      pad: 1
      stride: 1
      bias_term: false
	  weight_filler { type: "msra" std: 0.010 }
      }
}

layer {
  bottom: "res3b_branch2a"
    top: "res3b_branch2a"
    name: "bn3b_branch2a"
    type: "BatchNorm"
    
	param { lr_mult: 0 }
    param { lr_mult: 0 }
    param { lr_mult: 0 }
}

layer {
  bottom: "res3b_branch2a"
    top: "res3b_branch2a"
    name: "scale3b_branch2a"
    type: "Scale"
    scale_param {
    bias_term: true
      }
	param { lr_mult: 0 }
}

layer {
  bottom: "res3b_branch2a"
    top: "res3b_branch2a"
    name: "res3b_branch2a_relu"
    type: "ReLU"
    }

layer {
  bottom: "res3b_branch2a"
    top: "res3b_branch2b"
    name: "res3b_branch2b"
    type: "Convolution"
    convolution_param {
    num_output: 64
      kernel_size: 3
      pad: 1
      stride: 1
      bias_term: false
	  weight_filler { type: "msra" std: 0.010 }
      }
}

layer {
  bottom: "res3b_branch2b"
    top: "res3b_branch2b"
    name: "bn3b_branch2b"
    type: "BatchNorm"
    
	param { lr_mult: 0 }
    param { lr_mult: 0 }
    param { lr_mult: 0 }
}

layer {
  bottom: "res3b_branch2b"
    top: "res3b_branch2b"
    name: "scale3b_branch2b"
    type: "Scale"
    scale_param {
    bias_term: true
      }
	param { lr_mult: 0 }
}

layer {
  bottom: "res3a"
    bottom: "res3b_branch2b"
    top: "res3b"
    name: "res3b"
    type: "Eltwise"
    }

layer {
  bottom: "res3b"
    top: "res3b"
    name: "res3b_relu"
    type: "ReLU"
    }
##########################
######third shortcut#####
##########################

layer {
  bottom: "res3b"
    top: "res4a_branch1"
    name: "res4a_branch1"
    type: "Convolution"
    convolution_param {
    num_output: 128
      kernel_size: 1
      pad: 0
      stride: 1
      bias_term: false
	  weight_filler { type: "msra" std: 0.010 }
      }
}

layer {
  bottom: "res4a_branch1"
    top: "res4a_branch1"
    name: "bn4a_branch1"
    type: "BatchNorm"
    
	param { lr_mult: 0 }
    param { lr_mult: 0 }
    param { lr_mult: 0 }
}

layer {
  bottom: "res4a_branch1"
    top: "res4a_branch1"
    name: "scale4a_branch1"
    type: "Scale"
    scale_param {
    bias_term: true
      }
	param { lr_mult: 0 }
}

layer {
  bottom: "res3b"
    top: "res4a_branch2a"
    name: "res4a_branch2a"
    type: "Convolution"
    convolution_param {
    num_output: 64
      kernel_size: 3
      pad: 1
      stride: 1
      bias_term: false
	  weight_filler { type: "msra" std: 0.010 }
      }
}

layer {
  bottom: "res4a_branch2a"
    top: "res4a_branch2a"
    name: "bn4a_branch2a"
    type: "BatchNorm"
    
	param { lr_mult: 0 }
    param { lr_mult: 0 }
    param { lr_mult: 0 }
}

layer {
  bottom: "res4a_branch2a"
    top: "res4a_branch2a"
    name: "scale4a_branch2a"
    type: "Scale"
    scale_param {
    bias_term: true
      }
	param { lr_mult: 0 }
}

layer {
  bottom: "res4a_branch2a"
    top: "res4a_branch2a"
    name: "res4a_branch2a_relu"
    type: "ReLU"
    }

layer {
  bottom: "res4a_branch2a"
    top: "res4a_branch2b"
    name: "res4a_branch2b"
    type: "Convolution"
    convolution_param {
    num_output: 128
      kernel_size: 3
      pad: 1
      stride: 1
      bias_term: false
	  weight_filler { type: "msra" std: 0.010 }
      }
}

layer {
  bottom: "res4a_branch2b"
    top: "res4a_branch2b"
    name: "bn4a_branch2b"
    type: "BatchNorm"
    
	param { lr_mult: 0 }
    param { lr_mult: 0 }
    param { lr_mult: 0 }
}

layer {
  bottom: "res4a_branch2b"
    top: "res4a_branch2b"
    name: "scale4a_branch2b"
    type: "Scale"
    scale_param {
    bias_term: true
      }
	param { lr_mult: 0 }
}

layer {
  bottom: "res4a_branch1"
    bottom: "res4a_branch2b"
    top: "res4a"
    name: "res4a"
    type: "Eltwise"
    }

layer {
  bottom: "res4a"
    top: "res4a"
    name: "res4a_relu"
    type: "ReLU"
    }

layer {
  bottom: "res4a"
    top: "res4b_branch2a"
    name: "res4b_branch2a"
    type: "Convolution"
    convolution_param {
    num_output: 64
      kernel_size: 3
      pad: 1
      stride: 1
      bias_term: false
	  weight_filler { type: "msra" std: 0.010 }
      }
}

layer {
  bottom: "res4b_branch2a"
    top: "res4b_branch2a"
    name: "bn4b_branch2a"
    type: "BatchNorm"
    
	param { lr_mult: 0 }
    param { lr_mult: 0 }
    param { lr_mult: 0 }
}

layer {
  bottom: "res4b_branch2a"
    top: "res4b_branch2a"
    name: "scale4b_branch2a"
    type: "Scale"
    scale_param {
    bias_term: true
      }
	param { lr_mult: 0 }
}

layer {
  bottom: "res4b_branch2a"
    top: "res4b_branch2a"
    name: "res4b_branch2a_relu"
    type: "ReLU"
    }

layer {
  bottom: "res4b_branch2a"
    top: "res4b_branch2b"
    name: "res4b_branch2b"
    type: "Convolution"
    convolution_param {
    num_output: 128
      kernel_size: 3
      pad: 1
      stride: 1
      bias_term: false
	  weight_filler { type: "msra" std: 0.010 }
      }
}

layer {
  bottom: "res4b_branch2b"
    top: "res4b_branch2b"
    name: "bn4b_branch2b"
    type: "BatchNorm"
    
	param { lr_mult: 0 }
    param { lr_mult: 0 }
    param { lr_mult: 0 }
}

layer {
  bottom: "res4b_branch2b"
    top: "res4b_branch2b"
    name: "scale4b_branch2b"
    type: "Scale"
    scale_param {
    bias_term: true
      }
	param { lr_mult: 0 }
}

layer {
  bottom: "res4a"
    bottom: "res4b_branch2b"
    top: "res4b"
    name: "res4b"
    type: "Eltwise"
}

layer {
  bottom: "res4b"
    top: "res4b"
    name: "res4b_relu"
    type: "ReLU"
}
layer {
	name: "res4b_slice"
	type: "Slice"
	bottom: "res4b"
	top: "party_body_one"
	top: "party_body_two"
	top: "party_body_three"
	slice_param {
		slice_point: 16
		slice_point: 32
		axis: 2
	}
}
############branch_one#############
layer {
	name: "branch_one_gap"
	type: "Pooling"
	bottom: "res4b"
	top: "branch_one_gap"
	pooling_param {
		pool: AVE
		global_pooling: true
	}
}
layer {
	name: "branch_one_gmp"
	type: "Pooling"
	bottom: "res4b"
	top: "branch_one_gmp"
	pooling_param {
		pool: MAX
		global_pooling: true
	}
}

layer {
	bottom: "branch_one_gap"
	bottom: "branch_one_gmp"
	top: "branch_one"
	name: "branch_one"
	type: "Eltwise"
}

############branch_two#############
layer {
	name: "stage_two_one"
	type: "Concat"
	bottom: "party_body_one"
	bottom: "party_body_two"
	top: "stage_two_one"
	concat_param {
		axis: 2
	}
}
layer {
	name: "branch_two_gap"
	type: "Pooling"
	bottom: "stage_two_one"
	top: "branch_two_gap"
	pooling_param {
		pool: AVE
		global_pooling: true
	}
}
layer {
	name: "branch_two_gmp"
	type: "Pooling"
	bottom: "stage_two_one"
	top: "branch_two_gmp"
	pooling_param {
		pool: MAX
		global_pooling: true
	}
}

layer {
	bottom: "branch_two_gap"
	bottom: "branch_two_gmp"
	top: "branch_two"
	name: "branch_two"
	type: "Eltwise"
}

############branch_three#############
layer {
	name: "stage_two_two"
	type: "Concat"
	bottom: "party_body_two"
	bottom: "party_body_three"
	top: "stage_two_two"
	concat_param {
		axis: 2
	}
}
layer {
	name: "branch_three_gap"
	type: "Pooling"
	bottom: "stage_two_two"
	top: "branch_three_gap"
	pooling_param {
		pool: AVE
		global_pooling: true
	}
}
layer {
	name: "branch_three_gmp"
	type: "Pooling"
	bottom: "stage_two_two"
	top: "branch_three_gmp"
	pooling_param {
		pool: MAX
		global_pooling: true
	}
}

layer {
	bottom: "branch_three_gap"
	bottom: "branch_three_gmp"
	top: "branch_three"
	name: "branch_three"
	type: "Eltwise"
}

############branch_four#############
layer {
	name: "branch_four_gap"
	type: "Pooling"
	bottom: "party_body_one"
	top: "branch_four_gap"
	pooling_param {
		pool: AVE
		global_pooling: true
	}
}
layer {
	name: "branch_four_gmp"
	type: "Pooling"
	bottom: "party_body_one"
	top: "branch_four_gmp"
	pooling_param {
		pool: MAX
		global_pooling: true
	}
}

layer {
	bottom: "branch_four_gap"
	bottom: "branch_four_gmp"
	top: "branch_four"
	name: "branch_four"
	type: "Eltwise"
}

############branch_five#############
layer {
	name: "branch_five_gap"
	type: "Pooling"
	bottom: "party_body_two"
	top: "branch_five_gap"
	pooling_param {
		pool: AVE
		global_pooling: true
	}
}
layer {
	name: "branch_five_gmp"
	type: "Pooling"
	bottom: "party_body_two"
	top: "branch_five_gmp"
	pooling_param {
		pool: MAX
		global_pooling: true
	}
}

layer {
	bottom: "branch_five_gap"
	bottom: "branch_five_gmp"
	top: "branch_five"
	name: "branch_five"
	type: "Eltwise"
}

############branch_six#############
layer {
	name: "branch_six_gap"
	type: "Pooling"
	bottom: "party_body_three"
	top: "branch_six_gap"
	pooling_param {
		pool: AVE
		global_pooling: true
	}
}
layer {
	name: "branch_six_gmp"
	type: "Pooling"
	bottom: "party_body_three"
	top: "branch_six_gmp"
	pooling_param {
		pool: MAX
		global_pooling: true
	}
}

layer {
	bottom: "branch_six_gap"
	bottom: "branch_six_gmp"
	top: "branch_six"
	name: "branch_six"
	type: "Eltwise"
}

layer {
	name: "fc5"
	type: "Concat"
	bottom: "branch_one"
	bottom: "branch_two"
	bottom: "branch_three"
	bottom: "branch_four"
	bottom: "branch_five"
	bottom: "branch_six"
	top: "fc5"
}
