name: "deepFace"
input: "data"
input_shape {
	dim: 1
	dim: 3
	dim: 640
	dim: 640
}

layer {
	name: "conv1"
	type: "Convolution"
	bottom: "data"
	top: "conv1"
	param {
		lr_mult: 1.0
		decay_mult: 1.0
	}
	convolution_param {
		num_output: 64
		bias_term: false
		kernel_size: 3
		pad: 1
		weight_filler {
			type: "msra"
		}
	}
}
layer {
	name: "conv1/bn"
	type: "BatchNorm"
	bottom: "conv1"
	top: "conv1"
	param {
		lr_mult: 0
		decay_mult: 0
	}
	param {
		lr_mult: 0
		decay_mult: 0
	}
	param {
		lr_mult: 0
		decay_mult: 0
	}
	batch_norm_param {
		use_global_stats: true
	}
}
layer {
	name: "conv1/scale"
	type: "Scale"
	bottom: "conv1"
	top: "conv1"
	param {
		lr_mult: 1.0
		decay_mult: 0.0
	}
	param {
		lr_mult: 2.0
		decay_mult: 0.0
	}
	scale_param {
		filler {
			value: 1
		}
		bias_term: true
		bias_filler {
			value: 0
		}
	}
}
layer {
	name: "conv1/relu"
	type: "ReLU"
	bottom: "conv1"
	top: "conv1"
}

layer {
	name: "conv2"
	type: "Convolution"
	bottom: "conv1"
	top: "conv2"
	param {
		lr_mult: 1.0
		decay_mult: 1.0
	}
	convolution_param {
		num_output: 128
		bias_term: false
		kernel_size: 3
		stride: 2
		pad: 1
		weight_filler {
			type: "msra"
		}
	}
}
layer {
	name: "conv2/bn"
	type: "BatchNorm"
	bottom: "conv2"
	top: "conv2"
	param {
		lr_mult: 0
		decay_mult: 0
	}
	param {
		lr_mult: 0
		decay_mult: 0
	}
	param {
		lr_mult: 0
		decay_mult: 0
	}
	batch_norm_param {
		use_global_stats: true
	}
}
layer {
	name: "conv2/scale"
	type: "Scale"
	bottom: "conv2"
	top: "conv2"
	param {
		lr_mult: 1.0
		decay_mult: 0.0
	}
	param {
		lr_mult: 2.0
		decay_mult: 0.0
	}
	scale_param {
		filler {
			value: 1
		}
		bias_term: true
		bias_filler {
			value: 0
		}
	}
}
layer {
	name: "conv2/relu"
	type: "ReLU"
	bottom: "conv2"
	top: "conv2"
}

layer {
	name: "conv3"
	type: "Convolution"
	bottom: "conv2"
	top: "conv3"
	param {
		lr_mult: 1.0
		decay_mult: 1.0
	}
	convolution_param {
		num_output: 128
		bias_term: false
		kernel_size: 3
		stride: 2
		pad: 1
		weight_filler {
			type: "msra"
		}
	}
}
layer {
	name: "conv3/bn"
	type: "BatchNorm"
	bottom: "conv3"
	top: "conv3"
	param {
		lr_mult: 0
		decay_mult: 0
	}
	param {
		lr_mult: 0
		decay_mult: 0
	}
	param {
		lr_mult: 0
		decay_mult: 0
	}
	batch_norm_param {
		use_global_stats: true
	}
}
layer {
	name: "conv3/scale"
	type: "Scale"
	bottom: "conv3"
	top: "conv3"
	param {
		lr_mult: 1.0
		decay_mult: 0.0
	}
	param {
		lr_mult: 2.0
		decay_mult: 0.0
	}
	scale_param {
		filler {
			value: 1
		}
		bias_term: true
		bias_filler {
			value: 0
		}
	}
}
#layer {
#	name: "conv3/relu"
#	type: "ReLU"
#	bottom: "conv3"
#	top: "conv3"
#}

layer {
	name: "conv4"
	type: "Convolution"
	bottom: "conv3"
	top: "conv4"
	param {
		lr_mult: 1.0
		decay_mult: 1.0
	}
	convolution_param {
		num_output: 128
		bias_term: false
		kernel_size: 3
		stride: 1
		pad: 1
		weight_filler {
			type: "msra"
		}
	}
}
layer {
	name: "conv4/bn"
	type: "BatchNorm"
	bottom: "conv4"
	top: "conv4"
	param {
		lr_mult: 0
		decay_mult: 0
	}
	param {
		lr_mult: 0
		decay_mult: 0
	}
	param {
		lr_mult: 0
		decay_mult: 0
	}
	batch_norm_param {
		use_global_stats: true
	}
}
layer {
	name: "conv4/scale"
	type: "Scale"
	bottom: "conv4"
	top: "conv4"
	param {
		lr_mult: 1.0
		decay_mult: 0.0
	}
	param {
		lr_mult: 2.0
		decay_mult: 0.0
	}
	scale_param {
		filler {
			value: 1
		}
		bias_term: true
		bias_filler {
			value: 0
		}
	}
}
layer {
	name: "conv4/relu"
	type: "ReLU"
	bottom: "conv4"
	top: "conv4"
}
layer {
	name: "conv5"
	type: "Convolution"
	bottom: "conv4"
	top: "conv5"
	param {
		lr_mult: 1.0
		decay_mult: 1.0
	}
	convolution_param {
		num_output: 128
		bias_term: false
		kernel_size: 3
		pad: 1
		weight_filler {
			type: "msra"
		}
	}
}
layer {
	name: "conv5/bn"
	type: "BatchNorm"
	bottom: "conv5"
	top: "conv5"
	param {
		lr_mult: 0
		decay_mult: 0
	}
	param {
		lr_mult: 0
		decay_mult: 0
	}
	param {
		lr_mult: 0
		decay_mult: 0
	}
	batch_norm_param {
		use_global_stats: true
	}
}
layer {
	name: "conv5/scale"
	type: "Scale"
	bottom: "conv5"
	top: "conv5"
	param {
		lr_mult: 1.0
		decay_mult: 0.0
	}
	param {
		lr_mult: 2.0
		decay_mult: 0.0
	}
	scale_param {
		filler {
			value: 1
		}
		bias_term: true
		bias_filler {
			value: 0
		}
	}
}
#layer {
#	name: "conv5/relu"
#	type: "ReLU"
#	bottom: "conv5"
#	top: "conv5"
#}
layer{
	name: "conv5_eltwise"
	type: "Eltwise"
	bottom: "conv3"
	bottom: "conv5"
	top: "conv5_eltwise"
	eltwise_param {
		operation: SUM
	}
}

layer {
	name: "conv6"
	type: "Convolution"
	bottom: "conv5_eltwise"
	top: "conv6"
	param {
		lr_mult: 1.0
		decay_mult: 1.0
	}
	convolution_param {
		num_output: 128
		bias_term: false
		kernel_size: 3
		pad: 1
		weight_filler {
			type: "msra"
		}
	}
}
layer {
	name: "conv6/bn"
	type: "BatchNorm"
	bottom: "conv6"
	top: "conv6"
	param {
		lr_mult: 0
		decay_mult: 0
	}
	param {
		lr_mult: 0
		decay_mult: 0
	}
	param {
		lr_mult: 0
		decay_mult: 0
	}
	batch_norm_param {
		use_global_stats: true
	}
}
layer {
	name: "conv6/scale"
	type: "Scale"
	bottom: "conv6"
	top: "conv6"
	param {
		lr_mult: 1.0
		decay_mult: 0.0
	}
	param {
		lr_mult: 2.0
		decay_mult: 0.0
	}
	scale_param {
		filler {
			value: 1
		}
		bias_term: true
		bias_filler {
			value: 0
		}
	}
}
layer {
	name: "conv6/relu"
	type: "ReLU"
	bottom: "conv6"
	top: "conv6"
}

layer {
	name: "conv7"
	type: "Convolution"
	bottom: "conv6"
	top: "conv7"
	param {
		lr_mult: 1.0
		decay_mult: 1.0
	}
	convolution_param {
		num_output: 128
		bias_term: false
		kernel_size: 3
		pad: 1
		weight_filler {
			type: "msra"
		}
	}
}
layer {
	name: "conv7/bn"
	type: "BatchNorm"
	bottom: "conv7"
	top: "conv7"
	param {
		lr_mult: 0
		decay_mult: 0
	}
	param {
		lr_mult: 0
		decay_mult: 0
	}
	param {
		lr_mult: 0
		decay_mult: 0
	}
	batch_norm_param {
		use_global_stats: true
	}
}
layer {
	name: "conv7/scale"
	type: "Scale"
	bottom: "conv7"
	top: "conv7"
	param {
		lr_mult: 1.0
		decay_mult: 0.0
	}
	param {
		lr_mult: 2.0
		decay_mult: 0.0
	}
	scale_param {
		filler {
			value: 1
		}
		bias_term: true
		bias_filler {
			value: 0
		}
	}
}
#layer {
#	name: "conv7/relu"
#	type: "ReLU"
#	bottom: "conv7"
#	top: "conv7"
#}
layer{
	name: "conv7_eltwise"
	type: "Eltwise"
	bottom: "conv5_eltwise"
	bottom: "conv7"
	top: "conv7_eltwise"
	eltwise_param {
		operation: SUM
	}
}

layer {
	name: "conv8"
	type: "Convolution"
	bottom: "conv7_eltwise"
	top: "conv8"
	param {
		lr_mult: 1.0
		decay_mult: 1.0
	}
	convolution_param {
		num_output: 128
		bias_term: false
		kernel_size: 3
		pad: 1
		weight_filler {
			type: "msra"
		}
	}
}
layer {
	name: "conv8/bn"
	type: "BatchNorm"
	bottom: "conv8"
	top: "conv8"
	param {
		lr_mult: 0
		decay_mult: 0
	}
	param {
		lr_mult: 0
		decay_mult: 0
	}
	param {
		lr_mult: 0
		decay_mult: 0
	}
	batch_norm_param {
		use_global_stats: true
	}
}
layer {
	name: "conv8/scale"
	type: "Scale"
	bottom: "conv8"
	top: "conv8"
	param {
		lr_mult: 1.0
		decay_mult: 0.0
	}
	param {
		lr_mult: 2.0
		decay_mult: 0.0
	}
	scale_param {
		filler {
			value: 1
		}
		bias_term: true
		bias_filler {
			value: 0
		}
	}
}
layer {
	name: "conv8/relu"
	type: "ReLU"
	bottom: "conv8"
	top: "conv8"
}

layer {
	name: "conv9"
	type: "Convolution"
	bottom: "conv8"
	top: "conv9"
	param {
		lr_mult: 1.0
		decay_mult: 1.0
	}
	convolution_param {
		num_output: 128
		bias_term: false
		kernel_size: 3
		pad: 1
		weight_filler {
			type: "msra"
		}
	}
}
layer {
	name: "conv9/bn"
	type: "BatchNorm"
	bottom: "conv9"
	top: "conv9"
	param {
		lr_mult: 0
		decay_mult: 0
	}
	param {
		lr_mult: 0
		decay_mult: 0
	}
	param {
		lr_mult: 0
		decay_mult: 0
	}
	batch_norm_param {
		use_global_stats: true
	}
}
layer {
	name: "conv9/scale"
	type: "Scale"
	bottom: "conv9"
	top: "conv9"
	param {
		lr_mult: 1.0
		decay_mult: 0.0
	}
	param {
		lr_mult: 2.0
		decay_mult: 0.0
	}
	scale_param {
		filler {
			value: 1
		}
		bias_term: true
		bias_filler {
			value: 0
		}
	}
}

layer{
	name: "conv9_eltwise"
	type: "Eltwise"
	bottom: "conv7_eltwise"
	bottom: "conv9"
	top: "conv9_eltwise"
	eltwise_param {
		operation: SUM
	}
}
layer {
	name: "conv10"
	type: "Convolution"
	bottom: "conv9_eltwise"
	top: "conv10"
	param {
		lr_mult: 1.0
		decay_mult: 1.0
	}
	convolution_param {
		num_output: 128
		bias_term: false
		kernel_size: 3
		pad: 1
		weight_filler {
			type: "msra"
		}
	}
}
layer {
	name: "conv10/bn"
	type: "BatchNorm"
	bottom: "conv10"
	top: "conv10"
	param {
		lr_mult: 0
		decay_mult: 0
	}
	param {
		lr_mult: 0
		decay_mult: 0
	}
	param {
		lr_mult: 0
		decay_mult: 0
	}
	batch_norm_param {
		use_global_stats: true
	}
}
layer {
	name: "conv10/scale"
	type: "Scale"
	bottom: "conv10"
	top: "conv10"
	param {
		lr_mult: 1.0
		decay_mult: 0.0
	}
	param {
		lr_mult: 2.0
		decay_mult: 0.0
	}
	scale_param {
		filler {
			value: 1
		}
		bias_term: true
		bias_filler {
			value: 0
		}
	}
}
layer {
	name: "conv10/relu"
	type: "ReLU"
	bottom: "conv10"
	top: "conv10"
}
layer {
	name: "conv11"
	type: "Convolution"
	bottom: "conv10"
	top: "conv11"
	param {
		lr_mult: 1.0
		decay_mult: 1.0
	}
	convolution_param {
		num_output: 128
		bias_term: false
		kernel_size: 3
		pad: 1
		weight_filler {
			type: "msra"
		}
	}
}
layer {
	name: "conv11/bn"
	type: "BatchNorm"
	bottom: "conv11"
	top: "conv11"
	param {
		lr_mult: 0
		decay_mult: 0
	}
	param {
		lr_mult: 0
		decay_mult: 0
	}
	param {
		lr_mult: 0
		decay_mult: 0
	}
	batch_norm_param {
		use_global_stats: true
	}
}
layer {
	name: "conv11/scale"
	type: "Scale"
	bottom: "conv11"
	top: "conv11"
	param {
		lr_mult: 1.0
		decay_mult: 0.0
	}
	param {
		lr_mult: 2.0
		decay_mult: 0.0
	}
	scale_param {
		filler {
			value: 1
		}
		bias_term: true
		bias_filler {
			value: 0
		}
	}
}

layer{
	name: "conv11_eltwise"
	type: "Eltwise"
	bottom: "conv9_eltwise"
	bottom: "conv11"
	top: "conv11_eltwise"
	eltwise_param {
		operation: SUM
	}
}

layer {
	name: "conv12/dw"
	type: "Convolution"
	bottom: "conv11_eltwise"
	top: "conv12/dw"
	param {
		lr_mult: 1.0
		decay_mult: 1.0
	}
	convolution_param {
		num_output: 128
		bias_term: false
		kernel_size: 3
		pad: 1
		stride: 2
		group: 128
		weight_filler {
			type: "msra"
		}
	}
}
layer {
	name: "conv12/dw/bn"
	type: "BatchNorm"
	bottom: "conv12/dw"
	top: "conv12/dw"
	param {
		lr_mult: 0
		decay_mult: 0
	}
	param {
		lr_mult: 0
		decay_mult: 0
	}
	param {
		lr_mult: 0
		decay_mult: 0
	}
	batch_norm_param {
		use_global_stats: true
	}
}
layer {
	name: "conv12/dw/scale"
	type: "Scale"
	bottom: "conv12/dw"
	top: "conv12/dw"
	param {
		lr_mult: 1.0
		decay_mult: 0.0
	}
	param {
		lr_mult: 2.0
		decay_mult: 0.0
	}
	scale_param {
		filler {
			value: 1
		}
		bias_term: true
		bias_filler {
			value: 0
		}
	}
}
layer {
	name: "conv12/dw/relu"
	type: "ReLU"
	bottom: "conv12/dw"
	top: "conv12/dw"
}
layer {
	name: "conv12"
	type: "Convolution"
	bottom: "conv12/dw"
	top: "conv12"
	param {
		lr_mult: 1.0
		decay_mult: 1.0
	}
	convolution_param {
		num_output: 128
		bias_term: false
		kernel_size: 1
		weight_filler {
			type: "msra"
		}
	}
}
layer {
	name: "conv12/bn"
	type: "BatchNorm"
	bottom: "conv12"
	top: "conv12"
	param {
		lr_mult: 0
		decay_mult: 0
	}
	param {
		lr_mult: 0
		decay_mult: 0
	}
	param {
		lr_mult: 0
		decay_mult: 0
	}
	batch_norm_param {
		use_global_stats: true
	}
}
layer {
	name: "conv12/scale"
	type: "Scale"
	bottom: "conv12"
	top: "conv12"
	param {
		lr_mult: 1.0
		decay_mult: 0.0
	}
	param {
		lr_mult: 2.0
		decay_mult: 0.0
	}
	scale_param {
		filler {
			value: 1
		}
		bias_term: true
		bias_filler {
			value: 0
		}
	}
}
layer {
	name: "conv13/dw"
	type: "Convolution"
	bottom: "conv12"
	top: "conv13/dw"
	param {
		lr_mult: 1.0
		decay_mult: 1.0
	}
	convolution_param {
		num_output: 128
		bias_term: false
		kernel_size: 3
		pad: 1
		stride: 1
		group: 128
		weight_filler {
			type: "msra"
		}
	}
}
layer {
	name: "conv13/dw/bn"
	type: "BatchNorm"
	bottom: "conv13/dw"
	top: "conv13/dw"
	param {
		lr_mult: 0
		decay_mult: 0
	}
	param {
		lr_mult: 0
		decay_mult: 0
	}
	param {
		lr_mult: 0
		decay_mult: 0
	}
	batch_norm_param {
		use_global_stats: true
	}
}
layer {
	name: "conv13/dw/scale"
	type: "Scale"
	bottom: "conv13/dw"
	top: "conv13/dw"
	param {
		lr_mult: 1.0
		decay_mult: 0.0
	}
	param {
		lr_mult: 2.0
		decay_mult: 0.0
	}
	scale_param {
		filler {
			value: 1
		}
		bias_term: true
		bias_filler {
			value: 0
		}
	}
}
layer {
	name: "conv13/dw/relu"
	type: "ReLU"
	bottom: "conv13/dw"
	top: "conv13/dw"
}
layer {
	name: "conv13"
	type: "Convolution"
	bottom: "conv13/dw"
	top: "conv13"
	param {
		lr_mult: 1.0
		decay_mult: 1.0
	}
	convolution_param {
		num_output: 128
		bias_term: false
		kernel_size: 1
		weight_filler {
			type: "msra"
		}
	}
}
layer {
	name: "conv13/bn"
	type: "BatchNorm"
	bottom: "conv13"
	top: "conv13"
	param {
		lr_mult: 0
		decay_mult: 0
	}
	param {
		lr_mult: 0
		decay_mult: 0
	}
	param {
		lr_mult: 0
		decay_mult: 0
	}
	batch_norm_param {
		use_global_stats: true
	}
}
layer {
	name: "conv13/scale"
	type: "Scale"
	bottom: "conv13"
	top: "conv13"
	param {
		lr_mult: 1.0
		decay_mult: 0.0
	}
	param {
		lr_mult: 2.0
		decay_mult: 0.0
	}
	scale_param {
		filler {
			value: 1
		}
		bias_term: true
		bias_filler {
			value: 0
		}
	}
}
layer {
	name: "conv13/relu"
	type: "ReLU"
	bottom: "conv13"
	top: "conv13"
}
layer {
	name: "conv14/dw"
	type: "Convolution"
	bottom: "conv13"
	top: "conv14/dw"
	param {
		lr_mult: 1.0
		decay_mult: 1.0
	}
	convolution_param {
		num_output: 128
		bias_term: false
		kernel_size: 3
		pad: 1
		stride: 1
		group: 128
		weight_filler {
			type: "msra"
		}
	}
}
layer {
	name: "conv14/dw/bn"
	type: "BatchNorm"
	bottom: "conv14/dw"
	top: "conv14/dw"
	param {
		lr_mult: 0
		decay_mult: 0
	}
	param {
		lr_mult: 0
		decay_mult: 0
	}
	param {
		lr_mult: 0
		decay_mult: 0
	}
	batch_norm_param {
		use_global_stats: true
	}
}
layer {
	name: "conv14/dw/scale"
	type: "Scale"
	bottom: "conv14/dw"
	top: "conv14/dw"
	param {
		lr_mult: 1.0
		decay_mult: 0.0
	}
	param {
		lr_mult: 2.0
		decay_mult: 0.0
	}
	scale_param {
		filler {
			value: 1
		}
		bias_term: true
		bias_filler {
			value: 0
		}
	}
}
layer {
	name: "conv14/dw/relu"
	type: "ReLU"
	bottom: "conv14/dw"
	top: "conv14/dw"
}
layer {
	name: "conv14"
	type: "Convolution"
	bottom: "conv14/dw"
	top: "conv14"
	param {
		lr_mult: 1.0
		decay_mult: 1.0
	}
	convolution_param {
		num_output: 128
		bias_term: false
		kernel_size: 1
		weight_filler {
			type: "msra"
		}
	}
}
layer {
	name: "conv14/bn"
	type: "BatchNorm"
	bottom: "conv14"
	top: "conv14"
	param {
		lr_mult: 0
		decay_mult: 0
	}
	param {
		lr_mult: 0
		decay_mult: 0
	}
	param {
		lr_mult: 0
		decay_mult: 0
	}
	batch_norm_param {
		use_global_stats: true
	}
}
layer {
	name: "conv14/scale"
	type: "Scale"
	bottom: "conv14"
	top: "conv14"
	param {
		lr_mult: 1.0
		decay_mult: 0.0
	}
	param {
		lr_mult: 2.0
		decay_mult: 0.0
	}
	scale_param {
		filler {
			value: 1
		}
		bias_term: true
		bias_filler {
			value: 0
		}
	}
}

layer{
	name: "conv14_eltwise"
	type: "Eltwise"
	bottom: "conv12"
	bottom: "conv14"
	top: "conv14_eltwise"
	eltwise_param {
		operation: SUM
	}
}

layer {
	name: "conv15/dw"
	type: "Convolution"
	bottom: "conv14_eltwise"
	top: "conv15/dw"
	param {
		lr_mult: 1.0
		decay_mult: 1.0
	}
	convolution_param {
		num_output: 128
		bias_term: false
		kernel_size: 3
		pad: 1
		stride: 1
		group: 128
		weight_filler {
			type: "msra"
		}
	}
}
layer {
	name: "conv15/dw/bn"
	type: "BatchNorm"
	bottom: "conv15/dw"
	top: "conv15/dw"
	param {
		lr_mult: 0
		decay_mult: 0
	}
	param {
		lr_mult: 0
		decay_mult: 0
	}
	param {
		lr_mult: 0
		decay_mult: 0
	}
	batch_norm_param {
		use_global_stats: true
	}
}
layer {
	name: "conv15/dw/scale"
	type: "Scale"
	bottom: "conv15/dw"
	top: "conv15/dw"
	param {
		lr_mult: 1.0
		decay_mult: 0.0
	}
	param {
		lr_mult: 2.0
		decay_mult: 0.0
	}
	scale_param {
		filler {
			value: 1
		}
		bias_term: true
		bias_filler {
			value: 0
		}
	}
}
layer {
	name: "conv15/dw/relu"
	type: "ReLU"
	bottom: "conv15/dw"
	top: "conv15/dw"
}
layer {
	name: "conv15"
	type: "Convolution"
	bottom: "conv15/dw"
	top: "conv15"
	param {
		lr_mult: 1.0
		decay_mult: 1.0
	}
	convolution_param {
		num_output: 128
		bias_term: false
		kernel_size: 1
		weight_filler {
			type: "msra"
		}
	}
}
layer {
	name: "conv15/bn"
	type: "BatchNorm"
	bottom: "conv15"
	top: "conv15"
	param {
		lr_mult: 0
		decay_mult: 0
	}
	param {
		lr_mult: 0
		decay_mult: 0
	}
	param {
		lr_mult: 0
		decay_mult: 0
	}
	batch_norm_param {
		use_global_stats: true
	}
}
layer {
	name: "conv15/scale"
	type: "Scale"
	bottom: "conv15"
	top: "conv15"
	param {
		lr_mult: 1.0
		decay_mult: 0.0
	}
	param {
		lr_mult: 2.0
		decay_mult: 0.0
	}
	scale_param {
		filler {
			value: 1
		}
		bias_term: true
		bias_filler {
			value: 0
		}
	}
}
layer {
	name: "conv15/relu"
	type: "ReLU"
	bottom: "conv15"
	top: "conv15"
}
layer {
	name: "conv16/dw"
	type: "Convolution"
	bottom: "conv15"
	top: "conv16/dw"
	param {
		lr_mult: 1.0
		decay_mult: 1.0
	}
	convolution_param {
		num_output: 128
		bias_term: false
		kernel_size: 3
		pad: 1
		stride: 1
		group: 128
		weight_filler {
			type: "msra"
		}
	}
}
layer {
	name: "conv16/dw/bn"
	type: "BatchNorm"
	bottom: "conv16/dw"
	top: "conv16/dw"
	param {
		lr_mult: 0
		decay_mult: 0
	}
	param {
		lr_mult: 0
		decay_mult: 0
	}
	param {
		lr_mult: 0
		decay_mult: 0
	}
	batch_norm_param {
		use_global_stats: true
	}
}
layer {
	name: "conv16/dw/scale"
	type: "Scale"
	bottom: "conv16/dw"
	top: "conv16/dw"
	param {
		lr_mult: 1.0
		decay_mult: 0.0
	}
	param {
		lr_mult: 2.0
		decay_mult: 0.0
	}
	scale_param {
		filler {
			value: 1
		}
		bias_term: true
		bias_filler {
			value: 0
		}
	}
}
layer {
	name: "conv16/dw/relu"
	type: "ReLU"
	bottom: "conv16/dw"
	top: "conv16/dw"
}
layer {
	name: "conv16"
	type: "Convolution"
	bottom: "conv16/dw"
	top: "conv16"
	param {
		lr_mult: 1.0
		decay_mult: 1.0
	}
	convolution_param {
		num_output: 128
		bias_term: false
		kernel_size: 1
		weight_filler {
			type: "msra"
		}
	}
}
layer {
	name: "conv16/bn"
	type: "BatchNorm"
	bottom: "conv16"
	top: "conv16"
	param {
		lr_mult: 0
		decay_mult: 0
	}
	param {
		lr_mult: 0
		decay_mult: 0
	}
	param {
		lr_mult: 0
		decay_mult: 0
	}
	batch_norm_param {
		use_global_stats: true
	}
}
layer {
	name: "conv16/scale"
	type: "Scale"
	bottom: "conv16"
	top: "conv16"
	param {
		lr_mult: 1.0
		decay_mult: 0.0
	}
	param {
		lr_mult: 2.0
		decay_mult: 0.0
	}
	scale_param {
		filler {
			value: 1
		}
		bias_term: true
		bias_filler {
			value: 0
		}
	}
}

layer{
	name: "conv16_eltwise"
	type: "Eltwise"
	bottom: "conv14_eltwise"
	bottom: "conv16"
	top: "conv16_eltwise"
	eltwise_param {
		operation: SUM
	}
}
layer {
	name: "conv17/dw"
	type: "Convolution"
	bottom: "conv16_eltwise"
	top: "conv17/dw"
	param {
		lr_mult: 1.0
		decay_mult: 1.0
	}
	convolution_param {
		num_output: 128
		bias_term: false
		kernel_size: 3
		pad: 1
		stride: 2
		group: 128
		weight_filler {
			type: "msra"
		}
	}
}
layer {
	name: "conv17/dw/bn"
	type: "BatchNorm"
	bottom: "conv17/dw"
	top: "conv17/dw"
	param {
		lr_mult: 0
		decay_mult: 0
	}
	param {
		lr_mult: 0
		decay_mult: 0
	}
	param {
		lr_mult: 0
		decay_mult: 0
	}
	batch_norm_param {
		use_global_stats: true
	}
}
layer {
	name: "conv17/dw/scale"
	type: "Scale"
	bottom: "conv17/dw"
	top: "conv17/dw"
	param {
		lr_mult: 1.0
		decay_mult: 0.0
	}
	param {
		lr_mult: 2.0
		decay_mult: 0.0
	}
	scale_param {
		filler {
			value: 1
		}
		bias_term: true
		bias_filler {
			value: 0
		}
	}
}
layer {
	name: "conv17/dw/relu"
	type: "ReLU"
	bottom: "conv17/dw"
	top: "conv17/dw"
}
layer {
	name: "conv17"
	type: "Convolution"
	bottom: "conv17/dw"
	top: "conv17"
	param {
		lr_mult: 1.0
		decay_mult: 1.0
	}
	convolution_param {
		num_output: 128
		bias_term: false
		kernel_size: 1
		weight_filler {
			type: "msra"
		}
	}
}
layer {
	name: "conv17/bn"
	type: "BatchNorm"
	bottom: "conv17"
	top: "conv17"
	param {
		lr_mult: 0
		decay_mult: 0
	}
	param {
		lr_mult: 0
		decay_mult: 0
	}
	param {
		lr_mult: 0
		decay_mult: 0
	}
	batch_norm_param {
		use_global_stats: true
	}
}
layer {
	name: "conv17/scale"
	type: "Scale"
	bottom: "conv17"
	top: "conv17"
	param {
		lr_mult: 1.0
		decay_mult: 0.0
	}
	param {
		lr_mult: 2.0
		decay_mult: 0.0
	}
	scale_param {
		filler {
			value: 1
		}
		bias_term: true
		bias_filler {
			value: 0
		}
	}
}
layer {
	name: "conv18/dw"
	type: "Convolution"
	bottom: "conv17"
	top: "conv18/dw"
	param {
		lr_mult: 1.0
		decay_mult: 1.0
	}
	convolution_param {
		num_output: 128
		bias_term: false
		kernel_size: 3
		pad: 1
		stride: 1
		group: 128
		weight_filler {
			type: "msra"
		}
	}
}
layer {
	name: "conv18/dw/bn"
	type: "BatchNorm"
	bottom: "conv18/dw"
	top: "conv18/dw"
	param {
		lr_mult: 0
		decay_mult: 0
	}
	param {
		lr_mult: 0
		decay_mult: 0
	}
	param {
		lr_mult: 0
		decay_mult: 0
	}
	batch_norm_param {
		use_global_stats: true
	}
}
layer {
	name: "conv18/dw/scale"
	type: "Scale"
	bottom: "conv18/dw"
	top: "conv18/dw"
	param {
		lr_mult: 1.0
		decay_mult: 0.0
	}
	param {
		lr_mult: 2.0
		decay_mult: 0.0
	}
	scale_param {
		filler {
			value: 1
		}
		bias_term: true
		bias_filler {
			value: 0
		}
	}
}
layer {
	name: "conv18/dw/relu"
	type: "ReLU"
	bottom: "conv18/dw"
	top: "conv18/dw"
}
layer {
	name: "conv18"
	type: "Convolution"
	bottom: "conv18/dw"
	top: "conv18"
	param {
		lr_mult: 1.0
		decay_mult: 1.0
	}
	convolution_param {
		num_output: 128
		bias_term: false
		kernel_size: 1
		weight_filler {
			type: "msra"
		}
	}
}
layer {
	name: "conv18/bn"
	type: "BatchNorm"
	bottom: "conv18"
	top: "conv18"
	param {
		lr_mult: 0
		decay_mult: 0
	}
	param {
		lr_mult: 0
		decay_mult: 0
	}
	param {
		lr_mult: 0
		decay_mult: 0
	}
	batch_norm_param {
		use_global_stats: true
	}
}
layer {
	name: "conv18/scale"
	type: "Scale"
	bottom: "conv18"
	top: "conv18"
	param {
		lr_mult: 1.0
		decay_mult: 0.0
	}
	param {
		lr_mult: 2.0
		decay_mult: 0.0
	}
	scale_param {
		filler {
			value: 1
		}
		bias_term: true
		bias_filler {
			value: 0
		}
	}
}
layer {
	name: "conv18/relu"
	type: "ReLU"
	bottom: "conv18"
	top: "conv18"
}
layer {
	name: "conv19/dw"
	type: "Convolution"
	bottom: "conv18"
	top: "conv19/dw"
	param {
		lr_mult: 1.0
		decay_mult: 1.0
	}
	convolution_param {
		num_output: 128
		bias_term: false
		kernel_size: 3
		pad: 1
		stride: 1
		group: 128
		weight_filler {
			type: "msra"
		}
	}
}
layer {
	name: "conv19/dw/bn"
	type: "BatchNorm"
	bottom: "conv19/dw"
	top: "conv19/dw"
	param {
		lr_mult: 0
		decay_mult: 0
	}
	param {
		lr_mult: 0
		decay_mult: 0
	}
	param {
		lr_mult: 0
		decay_mult: 0
	}
	batch_norm_param {
		use_global_stats: true
	}
}
layer {
	name: "conv19/dw/scale"
	type: "Scale"
	bottom: "conv19/dw"
	top: "conv19/dw"
	param {
		lr_mult: 1.0
		decay_mult: 0.0
	}
	param {
		lr_mult: 2.0
		decay_mult: 0.0
	}
	scale_param {
		filler {
			value: 1
		}
		bias_term: true
		bias_filler {
			value: 0
		}
	}
}
layer {
	name: "conv19/dw/relu"
	type: "ReLU"
	bottom: "conv19/dw"
	top: "conv19/dw"
}
layer {
	name: "conv19"
	type: "Convolution"
	bottom: "conv19/dw"
	top: "conv19"
	param {
		lr_mult: 1.0
		decay_mult: 1.0
	}
	convolution_param {
		num_output: 128
		bias_term: false
		kernel_size: 1
		weight_filler {
			type: "msra"
		}
	}
}
layer {
	name: "conv19/bn"
	type: "BatchNorm"
	bottom: "conv19"
	top: "conv19"
	param {
		lr_mult: 0
		decay_mult: 0
	}
	param {
		lr_mult: 0
		decay_mult: 0
	}
	param {
		lr_mult: 0
		decay_mult: 0
	}
	batch_norm_param {
		use_global_stats: true
	}
}
layer {
	name: "conv19/scale"
	type: "Scale"
	bottom: "conv19"
	top: "conv19"
	param {
		lr_mult: 1.0
		decay_mult: 0.0
	}
	param {
		lr_mult: 2.0
		decay_mult: 0.0
	}
	scale_param {
		filler {
			value: 1
		}
		bias_term: true
		bias_filler {
			value: 0
		}
	}
}

layer{
	name: "conv19_eltwise"
	type: "Eltwise"
	bottom: "conv17"
	bottom: "conv19"
	top: "conv19_eltwise"
	eltwise_param {
		operation: SUM
	}
}

layer {
	name: "conv20/dw"
	type: "Convolution"
	bottom: "conv19_eltwise"
	top: "conv20/dw"
	param {
		lr_mult: 1.0
		decay_mult: 1.0
	}
	convolution_param {
		num_output: 128
		bias_term: false
		kernel_size: 3
		pad: 1
		stride: 2
		group: 128
		weight_filler {
			type: "msra"
		}
	}
}
layer {
	name: "conv20/dw/bn"
	type: "BatchNorm"
	bottom: "conv20/dw"
	top: "conv20/dw"
	param {
		lr_mult: 0
		decay_mult: 0
	}
	param {
		lr_mult: 0
		decay_mult: 0
	}
	param {
		lr_mult: 0
		decay_mult: 0
	}
	batch_norm_param {
		use_global_stats: true
	}
}
layer {
	name: "conv20/dw/scale"
	type: "Scale"
	bottom: "conv20/dw"
	top: "conv20/dw"
	param {
		lr_mult: 1.0
		decay_mult: 0.0
	}
	param {
		lr_mult: 2.0
		decay_mult: 0.0
	}
	scale_param {
		filler {
			value: 1
		}
		bias_term: true
		bias_filler {
			value: 0
		}
	}
}
layer {
	name: "conv20/dw/relu"
	type: "ReLU"
	bottom: "conv20/dw"
	top: "conv20/dw"
}
layer {
	name: "conv20"
	type: "Convolution"
	bottom: "conv20/dw"
	top: "conv20"
	param {
		lr_mult: 1.0
		decay_mult: 1.0
	}
	convolution_param {
		num_output: 128
		bias_term: false
		kernel_size: 1
		weight_filler {
			type: "msra"
		}
	}
}
layer {
	name: "conv20/bn"
	type: "BatchNorm"
	bottom: "conv20"
	top: "conv20"
	param {
		lr_mult: 0
		decay_mult: 0
	}
	param {
		lr_mult: 0
		decay_mult: 0
	}
	param {
		lr_mult: 0
		decay_mult: 0
	}
	batch_norm_param {
		use_global_stats: true
	}
}
layer {
	name: "conv20/scale"
	type: "Scale"
	bottom: "conv20"
	top: "conv20"
	param {
		lr_mult: 1.0
		decay_mult: 0.0
	}
	param {
		lr_mult: 2.0
		decay_mult: 0.0
	}
	scale_param {
		filler {
			value: 1
		}
		bias_term: true
		bias_filler {
			value: 0
		}
	}
}
layer {
	name: "conv21/dw"
	type: "Convolution"
	bottom: "conv20"
	top: "conv21/dw"
	param {
		lr_mult: 1.0
		decay_mult: 1.0
	}
	convolution_param {
		num_output: 128
		bias_term: false
		kernel_size: 3
		pad: 1
		stride: 1
		group: 128
		weight_filler {
			type: "msra"
		}
	}
}
layer {
	name: "conv21/dw/bn"
	type: "BatchNorm"
	bottom: "conv21/dw"
	top: "conv21/dw"
	param {
		lr_mult: 0
		decay_mult: 0
	}
	param {
		lr_mult: 0
		decay_mult: 0
	}
	param {
		lr_mult: 0
		decay_mult: 0
	}
	batch_norm_param {
		use_global_stats: true
	}
}
layer {
	name: "conv21/dw/scale"
	type: "Scale"
	bottom: "conv21/dw"
	top: "conv21/dw"
	param {
		lr_mult: 1.0
		decay_mult: 0.0
	}
	param {
		lr_mult: 2.0
		decay_mult: 0.0
	}
	scale_param {
		filler {
			value: 1
		}
		bias_term: true
		bias_filler {
			value: 0
		}
	}
}
layer {
	name: "conv21/dw/relu"
	type: "ReLU"
	bottom: "conv21/dw"
	top: "conv21/dw"
}
layer {
	name: "conv21"
	type: "Convolution"
	bottom: "conv21/dw"
	top: "conv21"
	param {
		lr_mult: 1.0
		decay_mult: 1.0
	}
	convolution_param {
		num_output: 128
		bias_term: false
		kernel_size: 1
		weight_filler {
			type: "msra"
		}
	}
}
layer {
	name: "conv21/bn"
	type: "BatchNorm"
	bottom: "conv21"
	top: "conv21"
	param {
		lr_mult: 0
		decay_mult: 0
	}
	param {
		lr_mult: 0
		decay_mult: 0
	}
	param {
		lr_mult: 0
		decay_mult: 0
	}
	batch_norm_param {
		use_global_stats: true
	}
}
layer {
	name: "conv21/scale"
	type: "Scale"
	bottom: "conv21"
	top: "conv21"
	param {
		lr_mult: 1.0
		decay_mult: 0.0
	}
	param {
		lr_mult: 2.0
		decay_mult: 0.0
	}
	scale_param {
		filler {
			value: 1
		}
		bias_term: true
		bias_filler {
			value: 0
		}
	}
}
layer {
	name: "conv21/relu"
	type: "ReLU"
	bottom: "conv21"
	top: "conv21"
}
layer {
	name: "conv22/dw"
	type: "Convolution"
	bottom: "conv21"
	top: "conv22/dw"
	param {
		lr_mult: 1.0
		decay_mult: 1.0
	}
	convolution_param {
		num_output: 128
		bias_term: false
		kernel_size: 3
		pad: 1
		stride: 1
		group: 128
		weight_filler {
			type: "msra"
		}
	}
}
layer {
	name: "conv22/dw/bn"
	type: "BatchNorm"
	bottom: "conv22/dw"
	top: "conv22/dw"
	param {
		lr_mult: 0
		decay_mult: 0
	}
	param {
		lr_mult: 0
		decay_mult: 0
	}
	param {
		lr_mult: 0
		decay_mult: 0
	}
	batch_norm_param {
		use_global_stats: true
	}
}
layer {
	name: "conv22/dw/scale"
	type: "Scale"
	bottom: "conv22/dw"
	top: "conv22/dw"
	param {
		lr_mult: 1.0
		decay_mult: 0.0
	}
	param {
		lr_mult: 2.0
		decay_mult: 0.0
	}
	scale_param {
		filler {
			value: 1
		}
		bias_term: true
		bias_filler {
			value: 0
		}
	}
}
layer {
	name: "conv22/dw/relu"
	type: "ReLU"
	bottom: "conv22/dw"
	top: "conv22/dw"
}
layer {
	name: "conv22"
	type: "Convolution"
	bottom: "conv22/dw"
	top: "conv22"
	param {
		lr_mult: 1.0
		decay_mult: 1.0
	}
	convolution_param {
		num_output: 128
		bias_term: false
		kernel_size: 1
		weight_filler {
			type: "msra"
		}
	}
}
layer {
	name: "conv22/bn"
	type: "BatchNorm"
	bottom: "conv22"
	top: "conv22"
	param {
		lr_mult: 0
		decay_mult: 0
	}
	param {
		lr_mult: 0
		decay_mult: 0
	}
	param {
		lr_mult: 0
		decay_mult: 0
	}
	batch_norm_param {
		use_global_stats: true
	}
}
layer {
	name: "conv22/scale"
	type: "Scale"
	bottom: "conv22"
	top: "conv22"
	param {
		lr_mult: 1.0
		decay_mult: 0.0
	}
	param {
		lr_mult: 2.0
		decay_mult: 0.0
	}
	scale_param {
		filler {
			value: 1
		}
		bias_term: true
		bias_filler {
			value: 0
		}
	}
}

layer{
	name: "conv22_eltwise"
	type: "Eltwise"
	bottom: "conv20"
	bottom: "conv22"
	top: "conv22_eltwise"
	eltwise_param {
		operation: SUM
	}
}

layer {
	name: "conv23/dw"
	type: "Convolution"
	bottom: "conv22_eltwise"
	top: "conv23/dw"
	param {
		lr_mult: 1.0
		decay_mult: 1.0
	}
	convolution_param {
		num_output: 128
		bias_term: false
		kernel_size: 3
		pad: 1
		stride: 1
		group: 128
		weight_filler {
			type: "msra"
		}
	}
}
layer {
	name: "conv23/dw/bn"
	type: "BatchNorm"
	bottom: "conv23/dw"
	top: "conv23/dw"
	param {
		lr_mult: 0
		decay_mult: 0
	}
	param {
		lr_mult: 0
		decay_mult: 0
	}
	param {
		lr_mult: 0
		decay_mult: 0
	}
	batch_norm_param {
		use_global_stats: true
	}
}
layer {
	name: "conv23/dw/scale"
	type: "Scale"
	bottom: "conv23/dw"
	top: "conv23/dw"
	param {
		lr_mult: 1.0
		decay_mult: 0.0
	}
	param {
		lr_mult: 2.0
		decay_mult: 0.0
	}
	scale_param {
		filler {
			value: 1
		}
		bias_term: true
		bias_filler {
			value: 0
		}
	}
}
layer {
	name: "conv23/dw/relu"
	type: "ReLU"
	bottom: "conv23/dw"
	top: "conv23/dw"
}
layer {
	name: "conv23"
	type: "Convolution"
	bottom: "conv23/dw"
	top: "conv23"
	param {
		lr_mult: 1.0
		decay_mult: 1.0
	}
	convolution_param {
		num_output: 128
		bias_term: false
		kernel_size: 1
		weight_filler {
			type: "msra"
		}
	}
}
layer {
	name: "conv23/bn"
	type: "BatchNorm"
	bottom: "conv23"
	top: "conv23"
	param {
		lr_mult: 0
		decay_mult: 0
	}
	param {
		lr_mult: 0
		decay_mult: 0
	}
	param {
		lr_mult: 0
		decay_mult: 0
	}
	batch_norm_param {
		use_global_stats: true
	}
}
layer {
	name: "conv23/scale"
	type: "Scale"
	bottom: "conv23"
	top: "conv23"
	param {
		lr_mult: 1.0
		decay_mult: 0.0
	}
	param {
		lr_mult: 2.0
		decay_mult: 0.0
	}
	scale_param {
		filler {
			value: 1
		}
		bias_term: true
		bias_filler {
			value: 0
		}
	}
}
layer {
	name: "conv23/relu"
	type: "ReLU"
	bottom: "conv23"
	top: "conv23"
}
layer {
	name: "conv24/dw"
	type: "Convolution"
	bottom: "conv23"
	top: "conv24/dw"
	param {
		lr_mult: 1.0
		decay_mult: 1.0
	}
	convolution_param {
		num_output: 128
		bias_term: false
		kernel_size: 3
		pad: 1
		stride: 1
		group: 128
		weight_filler {
			type: "msra"
		}
	}
}
layer {
	name: "conv24/dw/bn"
	type: "BatchNorm"
	bottom: "conv24/dw"
	top: "conv24/dw"
	param {
		lr_mult: 0
		decay_mult: 0
	}
	param {
		lr_mult: 0
		decay_mult: 0
	}
	param {
		lr_mult: 0
		decay_mult: 0
	}
	batch_norm_param {
		use_global_stats: true
	}
}
layer {
	name: "conv24/dw/scale"
	type: "Scale"
	bottom: "conv24/dw"
	top: "conv24/dw"
	param {
		lr_mult: 1.0
		decay_mult: 0.0
	}
	param {
		lr_mult: 2.0
		decay_mult: 0.0
	}
	scale_param {
		filler {
			value: 1
		}
		bias_term: true
		bias_filler {
			value: 0
		}
	}
}
layer {
	name: "conv24/dw/relu"
	type: "ReLU"
	bottom: "conv24/dw"
	top: "conv24/dw"
}
layer {
	name: "conv24"
	type: "Convolution"
	bottom: "conv24/dw"
	top: "conv24"
	param {
		lr_mult: 1.0
		decay_mult: 1.0
	}
	convolution_param {
		num_output: 128
		bias_term: false
		kernel_size: 1
		weight_filler {
			type: "msra"
		}
	}
}
layer {
	name: "conv24/bn"
	type: "BatchNorm"
	bottom: "conv24"
	top: "conv24"
	param {
		lr_mult: 0
		decay_mult: 0
	}
	param {
		lr_mult: 0
		decay_mult: 0
	}
	param {
		lr_mult: 0
		decay_mult: 0
	}
	batch_norm_param {
		use_global_stats: true
	}
}
layer {
	name: "conv24/scale"
	type: "Scale"
	bottom: "conv24"
	top: "conv24"
	param {
		lr_mult: 1.0
		decay_mult: 0.0
	}
	param {
		lr_mult: 2.0
		decay_mult: 0.0
	}
	scale_param {
		filler {
			value: 1
		}
		bias_term: true
		bias_filler {
			value: 0
		}
	}
}

layer{
	name: "conv24_eltwise"
	type: "Eltwise"
	bottom: "conv22_eltwise"
	bottom: "conv24"
	top: "conv24_eltwise"
	eltwise_param {
		operation: SUM
	}
}

layer {
	name: "conv25/dw"
	type: "Convolution"
	bottom: "conv24_eltwise"
	top: "conv25/dw"
	param {
		lr_mult: 1.0
		decay_mult: 1.0
	}
	convolution_param {
		num_output: 128
		bias_term: false
		kernel_size: 3
		pad: 1
		stride: 1
		group: 128
		weight_filler {
			type: "msra"
		}
	}
}
layer {
	name: "conv25/dw/bn"
	type: "BatchNorm"
	bottom: "conv25/dw"
	top: "conv25/dw"
	param {
		lr_mult: 0
		decay_mult: 0
	}
	param {
		lr_mult: 0
		decay_mult: 0
	}
	param {
		lr_mult: 0
		decay_mult: 0
	}
	batch_norm_param {
		use_global_stats: true
	}
}
layer {
	name: "conv25/dw/scale"
	type: "Scale"
	bottom: "conv25/dw"
	top: "conv25/dw"
	param {
		lr_mult: 1.0
		decay_mult: 0.0
	}
	param {
		lr_mult: 2.0
		decay_mult: 0.0
	}
	scale_param {
		filler {
			value: 1
		}
		bias_term: true
		bias_filler {
			value: 0
		}
	}
}
layer {
	name: "conv25/dw/relu"
	type: "ReLU"
	bottom: "conv25/dw"
	top: "conv25/dw"
}
layer {
	name: "conv25"
	type: "Convolution"
	bottom: "conv25/dw"
	top: "conv25"
	param {
		lr_mult: 1.0
		decay_mult: 1.0
	}
	convolution_param {
		num_output: 128
		bias_term: false
		kernel_size: 1
		weight_filler {
			type: "msra"
		}
	}
}
layer {
	name: "conv25/bn"
	type: "BatchNorm"
	bottom: "conv25"
	top: "conv25"
	param {
		lr_mult: 0
		decay_mult: 0
	}
	param {
		lr_mult: 0
		decay_mult: 0
	}
	param {
		lr_mult: 0
		decay_mult: 0
	}
	batch_norm_param {
		use_global_stats: true
	}
}
layer {
	name: "conv25/scale"
	type: "Scale"
	bottom: "conv25"
	top: "conv25"
	param {
		lr_mult: 1.0
		decay_mult: 0.0
	}
	param {
		lr_mult: 2.0
		decay_mult: 0.0
	}
	scale_param {
		filler {
			value: 1
		}
		bias_term: true
		bias_filler {
			value: 0
		}
	}
}
layer {
	name: "conv25/relu"
	type: "ReLU"
	bottom: "conv25"
	top: "conv25"
}
layer {
	name: "conv26/dw"
	type: "Convolution"
	bottom: "conv25"
	top: "conv26/dw"
	param {
		lr_mult: 1.0
		decay_mult: 1.0
	}
	convolution_param {
		num_output: 128
		bias_term: false
		kernel_size: 3
		pad: 1
		stride: 1
		group: 128
		weight_filler {
			type: "msra"
		}
	}
}
layer {
	name: "conv26/dw/bn"
	type: "BatchNorm"
	bottom: "conv26/dw"
	top: "conv26/dw"
	param {
		lr_mult: 0
		decay_mult: 0
	}
	param {
		lr_mult: 0
		decay_mult: 0
	}
	param {
		lr_mult: 0
		decay_mult: 0
	}
	batch_norm_param {
		use_global_stats: true
	}
}
layer {
	name: "conv26/dw/scale"
	type: "Scale"
	bottom: "conv26/dw"
	top: "conv26/dw"
	param {
		lr_mult: 1.0
		decay_mult: 0.0
	}
	param {
		lr_mult: 2.0
		decay_mult: 0.0
	}
	scale_param {
		filler {
			value: 1
		}
		bias_term: true
		bias_filler {
			value: 0
		}
	}
}
layer {
	name: "conv26/dw/relu"
	type: "ReLU"
	bottom: "conv26/dw"
	top: "conv26/dw"
}
layer {
	name: "conv26"
	type: "Convolution"
	bottom: "conv26/dw"
	top: "conv26"
	param {
		lr_mult: 1.0
		decay_mult: 1.0
	}
	convolution_param {
		num_output: 128
		bias_term: false
		kernel_size: 1
		weight_filler {
			type: "msra"
		}
	}
}
layer {
	name: "conv26/bn"
	type: "BatchNorm"
	bottom: "conv26"
	top: "conv26"
	param {
		lr_mult: 0
		decay_mult: 0
	}
	param {
		lr_mult: 0
		decay_mult: 0
	}
	param {
		lr_mult: 0
		decay_mult: 0
	}
	batch_norm_param {
		use_global_stats: true
	}
}
layer {
	name: "conv26/scale"
	type: "Scale"
	bottom: "conv26"
	top: "conv26"
	param {
		lr_mult: 1.0
		decay_mult: 0.0
	}
	param {
		lr_mult: 2.0
		decay_mult: 0.0
	}
	scale_param {
		filler {
			value: 1
		}
		bias_term: true
		bias_filler {
			value: 0
		}
	}
}

layer{
	name: "conv26_eltwise"
	type: "Eltwise"
	bottom: "conv24_eltwise"
	bottom: "conv26"
	top: "conv26_eltwise"
	eltwise_param {
		operation: SUM
	}
}

############################################################
#######################priorBox moudle two##################
############################################################
layer {
	name: "conv11_eltwise_priorbox"
	type: "PriorBox"
	bottom: "conv11_eltwise"
	bottom: "data"
	top: "conv11_eltwise_priorbox"
	prior_box_param {
		min_size: 10
		flip: true
		clip: false
		variance: 0.1
		variance: 0.1
		variance: 0.2
		variance: 0.2
		offset: 0.5
	}
}

layer {
	name: "conv11_eltwise_loc"
	type: "Convolution"
	bottom: "conv11_eltwise"
	top: "conv11_eltwise_loc"
	param {
		lr_mult: 1
		decay_mult: 1.0
	}
	param {
		lr_mult: 2
		decay_mult: 0
	}
	convolution_param {
		num_output: 4
		kernel_size: 1
		weight_filler {
			type: "msra"
		}
		bias_filler {
			type: "constant"
			value: 0.0
		}
	}
}
layer {
	name: "conv11_eltwise_loc_perm"
	type: "Permute"
	bottom: "conv11_eltwise_loc"
	top: "conv11_eltwise_loc_perm"
	permute_param {
		order: 0
		order: 2
		order: 3
		order: 1
	}
}
layer {
	name: "conv11_eltwise_loc_flat"
	type: "Flatten"
	bottom: "conv11_eltwise_loc_perm"
	top: "conv11_eltwise_loc_flat"
	flatten_param {
		axis: 1
	}
}

layer {
	name: "conv11_eltwise_conf_concat"
	type: "Convolution"
	bottom: "conv11_eltwise"
	top: "conv11_eltwise_conf_concat"
	param {
		lr_mult: 1
		decay_mult: 1.0
	}
	param {
		lr_mult: 2
		decay_mult: 0
	}
	convolution_param {
		num_output: 2
		kernel_size: 1
		weight_filler {
			type: "msra"
		}
		bias_filler {
			type: "constant"
			value: 0.0
		}
	}
}
layer {
	name: "conv11_eltwise_conf_concat_perm"
	type: "Permute"
	bottom: "conv11_eltwise_conf_concat"
	top: "conv11_eltwise_conf_concat_perm"
	permute_param {
		order: 0
		order: 2
		order: 3
		order: 1
	}
}
layer {
	name: "conv11_eltwise_conf_concat_flat"
	type: "Flatten"
	bottom: "conv11_eltwise_conf_concat_perm"
	top: "conv11_eltwise_conf_concat_flat"
	flatten_param {
		axis: 1
	}
}

############################################################
#######################priorBox moudle four ################
############################################################
layer {
	name: "conv16_eltwise_priorbox"
	type: "PriorBox"
	bottom: "conv16_eltwise"
	bottom: "data"
	top: "conv16_eltwise_priorbox"
	prior_box_param {
		min_size: 23
		min_size: 52
		flip: true
		clip: false
		variance: 0.1
		variance: 0.1
		variance: 0.2
		variance: 0.2
		offset: 0.5
	}
}

layer {
	name: "conv16_eltwise_loc"
	type: "Convolution"
	bottom: "conv16_eltwise"
	top: "conv16_eltwise_loc"
	param {
		lr_mult: 1
		decay_mult: 1.0
	}
	param {
		lr_mult: 2
		decay_mult: 0
	}
	convolution_param {
		num_output: 8
		kernel_size: 1
		weight_filler {
			type: "msra"
		}
		bias_filler {
			type: "constant"
			value: 0.0
		}
	}
}
layer {
	name: "conv16_eltwise_loc_perm"
	type: "Permute"
	bottom: "conv16_eltwise_loc"
	top: "conv16_eltwise_loc_perm"
	permute_param {
		order: 0
		order: 2
		order: 3
		order: 1
	}
}
layer {
	name: "conv16_eltwise_loc_flat"
	type: "Flatten"
	bottom: "conv16_eltwise_loc_perm"
	top: "conv16_eltwise_loc_flat"
	flatten_param {
		axis: 1
	}
}

layer {
	name: "conv16_eltwise_conf"
	type: "Convolution"
	bottom: "conv16_eltwise"
	top: "conv16_eltwise_conf"
	param {
		lr_mult: 1
		decay_mult: 1.0
	}
	param {
		lr_mult: 2
		decay_mult: 0
	}
	convolution_param {
		num_output: 4
		kernel_size: 1
		weight_filler {
			type: "msra"
		}
		bias_filler {
			type: "constant"
			value: 0.0
		}
	}
}
layer {
	name: "conv16_eltwise_conf_concat_perm"
	type: "Permute"
	bottom: "conv16_eltwise_conf"
	top: "conv16_eltwise_conf_concat_perm"
	permute_param {
		order: 0
		order: 2
		order: 3
		order: 1
	}
}
layer {
	name: "conv16_eltwise_conf_concat_flat"
	type: "Flatten"
	bottom: "conv16_eltwise_conf_concat_perm"
	top: "conv16_eltwise_conf_concat_flat"
	flatten_param {
		axis: 1
	}
}

############################################################
#######################priorBox moudle five ################
############################################################
layer {
	name: "dectction_moudle_five_priorbox"
	type: "PriorBox"
	bottom: "conv19_eltwise"
	bottom: "data"
	top: "dectction_moudle_five_priorbox"
	prior_box_param {
		min_size: 119.0
		flip: true
		clip: false
		variance: 0.1
		variance: 0.1
		variance: 0.2
		variance: 0.2
		offset: 0.5
	}
}

layer {
	name: "dectction_moudle_five_loc"
	type: "Convolution"
	bottom: "conv19_eltwise"
	top: "dectction_moudle_five_loc"
	param {
		lr_mult: 1
		decay_mult: 1.0
	}
	param {
		lr_mult: 2
		decay_mult: 0
	}
	convolution_param {
		num_output: 4
		kernel_size: 1
		weight_filler {
			type: "msra"
		}
		bias_filler {
			type: "constant"
			value: 0.0
		}
	}
}
layer {
	name: "dectction_moudle_five_loc_perm"
	type: "Permute"
	bottom: "dectction_moudle_five_loc"
	top: "dectction_moudle_five_loc_perm"
	permute_param {
		order: 0
		order: 2
		order: 3
		order: 1
	}
}
layer {
	name: "dectction_moudle_five_loc_flat"
	type: "Flatten"
	bottom: "dectction_moudle_five_loc_perm"
	top: "dectction_moudle_five_loc_flat"
	flatten_param {
		axis: 1
	}
}

layer {
	name: "dectction_moudle_five_conf"
	type: "Convolution"
	bottom: "conv19_eltwise"
	top: "dectction_moudle_five_conf"
	param {
		lr_mult: 1
		decay_mult: 1.0
	}
	param {
		lr_mult: 2
		decay_mult: 0
	}
	convolution_param {
		num_output: 2
		kernel_size: 1
		weight_filler {
			type: "msra"
		}
		bias_filler {
			type: "constant"
			value: 0.0
		}
	}
}
layer {
	name: "dectction_moudle_five_conf_concat_perm"
	type: "Permute"
	bottom: "dectction_moudle_five_conf"
	top: "dectction_moudle_five_conf_concat_perm"
	permute_param {
		order: 0
		order: 2
		order: 3
		order: 1
	}
}
layer {
	name: "dectction_moudle_five_conf_concat_flat"
	type: "Flatten"
	bottom: "dectction_moudle_five_conf_concat_perm"
	top: "dectction_moudle_five_conf_concat_flat"
	flatten_param {
		axis: 1
	}
}
############################################################
#######################priorBox moudle eight ################
############################################################
layer {
	name: "dectction_moudle_eight_priorbox"
	type: "PriorBox"
	bottom: "conv26_eltwise"
	bottom: "data"
	top: "dectction_moudle_eight_priorbox"
	prior_box_param {
		min_size: 268.0
		min_size: 596.0
		flip: true
		clip: false
		variance: 0.1
		variance: 0.1
		variance: 0.2
		variance: 0.2
		offset: 0.5
	}
}
layer {
	name: "dectction_moudle_eight_loc"
	type: "Convolution"
	bottom: "conv26_eltwise"
	top: "dectction_moudle_eight_loc"
	param {
		lr_mult: 1
		decay_mult: 1.0
	}
	param {
		lr_mult: 2
		decay_mult: 0
	}
	convolution_param {
		num_output: 8
		kernel_size: 1
		weight_filler {
			type: "msra"
		}
		bias_filler {
			type: "constant"
			value: 0.0
		}
	}
}
layer {
	name: "dectction_moudle_eight_loc_perm"
	type: "Permute"
	bottom: "dectction_moudle_eight_loc"
	top: "dectction_moudle_eight_loc_perm"
	permute_param {
		order: 0
		order: 2
		order: 3
		order: 1
	}
}
layer {
	name: "dectction_moudle_eight_loc_flat"
	type: "Flatten"
	bottom: "dectction_moudle_eight_loc_perm"
	top: "dectction_moudle_eight_loc_flat"
	flatten_param {
		axis: 1
	}
}

layer {
	name: "dectction_moudle_eight_conf"
	type: "Convolution"
	bottom: "conv26_eltwise"
	top: "dectction_moudle_eight_conf"
	param {
		lr_mult: 1
		decay_mult: 1.0
	}
	param {
		lr_mult: 2
		decay_mult: 0
	}
	convolution_param {
		num_output: 4
		kernel_size: 1
		weight_filler {
			type: "msra"
		}
		bias_filler {
			type: "constant"
			value: 0.0
		}
	}
}
layer {
	name: "dectction_moudle_eight_conf_concat_perm"
	type: "Permute"
	bottom: "dectction_moudle_eight_conf"
	top: "dectction_moudle_eight_conf_concat_perm"
	permute_param {
		order: 0
		order: 2
		order: 3
		order: 1
	}
}
layer {
	name: "dectction_moudle_eight_conf_concat_flat"
	type: "Flatten"
	bottom: "dectction_moudle_eight_conf_concat_perm"
	top: "dectction_moudle_eight_conf_concat_flat"
	flatten_param {
		axis: 1
	}
}
################################################
layer {
	name: "mbox_priorbox"
	type: "Concat"
	bottom: "conv11_eltwise_priorbox"
	bottom: "conv16_eltwise_priorbox"
	bottom: "dectction_moudle_five_priorbox"
	bottom: "dectction_moudle_eight_priorbox"
	top: "mbox_priorbox"
	concat_param {
		axis: 2
	}
}

layer {
	name: "mbox_loc"
	type: "Concat"
	bottom: "conv11_eltwise_loc_flat"
	bottom: "conv16_eltwise_loc_flat"
	bottom: "dectction_moudle_five_loc_flat"
	bottom: "dectction_moudle_eight_loc_flat"
	top: "mbox_loc"
	concat_param {
		axis: 1
	}
}


layer {
	name: "mbox_conf"
	type: "Concat"
	bottom: "conv11_eltwise_conf_concat_flat"
	bottom: "conv16_eltwise_conf_concat_flat"
	bottom: "dectction_moudle_five_conf_concat_flat"
	bottom: "dectction_moudle_eight_conf_concat_flat"
	top: "mbox_conf"
	concat_param {
		axis: 1
	}
}

layer {
	name: "mbox_conf_reshape"
	type: "Reshape"
	bottom: "mbox_conf"
	top: "mbox_conf_reshape"
	reshape_param {
		shape {
			dim: 0
			dim: -1
			dim: 2
		}
	}
}
layer {
	name: "mbox_conf_softmax"
	type: "Softmax"
	bottom: "mbox_conf_reshape"
	top: "mbox_conf_softmax"
	softmax_param {
		axis: 2
	}
}
layer {
	name: "mbox_conf_flatten"
	type: "Flatten"
	bottom: "mbox_conf_softmax"
	top: "mbox_conf_flatten"
	flatten_param {
		axis: 1
	}
}
layer {
	name: "detection_out"
	type: "DetectionOutput"
	bottom: "mbox_loc"
	bottom: "mbox_conf_flatten"
	bottom: "mbox_priorbox"
	top: "detection_out"
	include {
	phase: TEST
	}
	detection_output_param {
		num_classes: 2
		share_location: true
		background_label_id: 0
		nms_param {
			nms_threshold: 0.45
			top_k: 200
		}
		code_type: RECEPTIVE_CENTER
		keep_top_k: 100
		confidence_threshold: 0.15
	}
}
