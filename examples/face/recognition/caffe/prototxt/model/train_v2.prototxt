name: "faceRecognition"
layer {
	name: "data"
	type: "ImageData"
	top: "data"
	top: "label"
	top: "labelIndex"
	image_data_param {
		new_height: 128
		new_width: 128
		sample_num: 5
		label_num: 64
		batch_size: 320
		root_folder: "../../../../../../dataset/facedata/recognition/vggface/vggface2_align_train"
		source: "../scripts/labelmap.txt"
	}
	transform_param {
		mirror: true
		mean_value: 127.5
		mean_value: 127.5
		mean_value: 127.5
		scale: 0.0078125
		resize_param {
			prob: 1.0
			resize_mode: WARP
			height: 128
			width: 128
			interp_mode: LINEAR
			interp_mode: AREA
			interp_mode: NEAREST
			interp_mode: CUBIC
			interp_mode: LANCZOS4
		}
	}
}
layer {
	name: "conv_0"
	type: "Convolution"
	bottom: "data"
	top: "conv_0"
	param {
		lr_mult: 1
		decay_mult: 1
	}
	param {
		lr_mult: 2
		decay_mult: 0
	}
	convolution_param {
		num_output: 32
		kernel_size: 3
		stride: 1
		pad: 1
		weight_filler {
			type: "xavier"
		}
		bias_filler {
			type: "constant"
			value: 0
		}
	}
}
layer {
	name: "conv_0/bn"
	type: "BatchNorm"
	bottom: "conv_0"
	top: "conv_0"
	param {
		lr_mult: 0
		decay_mult: 0
	}
	param {
		lr_mult: 0
		decay_mult: 0
	}
	param {
		lr_mult: 0
		decay_mult: 0
	}
}
layer {
	name: "conv_0/scale"
	type: "Scale"
	bottom: "conv_0"
	top: "conv_0"
	param {
		lr_mult: 1.0
		decay_mult: 0.0
	}
	param {
		lr_mult: 2.0
		decay_mult: 0.0
	}
	scale_param {
		filler {
			value: 1
		}
		bias_term: true
		bias_filler {
			value: 0
		}
	}
}
layer {
	name: "conv_0/relu"
	type: "PReLU"
	bottom: "conv_0"
	top: "conv_0"
}
layer {
	name: "conv_1"
	type: "Convolution"
	bottom: "conv_0"
	top: "conv_1"
	param {
		lr_mult: 1
		decay_mult: 1
	}
	param {
		lr_mult: 2
		decay_mult: 0
	}
	convolution_param {
		num_output: 64
		kernel_size: 3
		stride: 2
		pad: 1
		weight_filler {
			type: "xavier"
		}
		bias_filler {
			type: "constant"
			value: 0
		}
	}
}
layer {
	name: "conv_1/bn"
	type: "BatchNorm"
	bottom: "conv_1"
	top: "conv_1"
	param {
		lr_mult: 0
		decay_mult: 0
	}
	param {
		lr_mult: 0
		decay_mult: 0
	}
	param {
		lr_mult: 0
		decay_mult: 0
	}
}
layer {
	name: "conv_1/scale"
	type: "Scale"
	bottom: "conv_1"
	top: "conv_1"
	param {
		lr_mult: 1.0
		decay_mult: 0.0
	}
	param {
		lr_mult: 2.0
		decay_mult: 0.0
	}
	scale_param {
		filler {
			value: 1
		}
		bias_term: true
		bias_filler {
			value: 0
		}
	}
}

layer {
	name: "conv_1_1"
	type: "Convolution"
	bottom: "conv_1"
	top: "conv_1_1"
	param {
		lr_mult: 1
		decay_mult: 1
	}
	param {
		lr_mult: 2
		decay_mult: 0
	}
	convolution_param {
		num_output: 64
		kernel_size: 3
		stride: 1
		pad: 1
		weight_filler {
			type: "xavier"
		}
		bias_filler {
			type: "constant"
			value: 0
		}
	}
}
layer {
	name: "conv_1_1/bn"
	type: "BatchNorm"
	bottom: "conv_1_1"
	top: "conv_1_1"
	param {
		lr_mult: 0
		decay_mult: 0
	}
	param {
		lr_mult: 0
		decay_mult: 0
	}
	param {
		lr_mult: 0
		decay_mult: 0
	}
}
layer {
	name: "conv_1_1/scale"
	type: "Scale"
	bottom: "conv_1_1"
	top: "conv_1_1"
	param {
		lr_mult: 1.0
		decay_mult: 0.0
	}
	param {
		lr_mult: 2.0
		decay_mult: 0.0
	}
	scale_param {
		filler {
			value: 1
		}
		bias_term: true
		bias_filler {
			value: 0
		}
	}
}
layer {
	name: "conv_one_eltwise"
	type: "Eltwise"
	bottom: "conv_1_1"
	bottom: "conv_1"
	top: "conv_one_eltwise"
	eltwise_param {
	operation: SUM
	}
}
layer {
	name: "conv_one_eltwise/relu"
	type: "PReLU"
	bottom: "conv_one_eltwise"
	top: "conv_one_eltwise"
}

layer {
	name: "conv_2"
	type: "Convolution"
	bottom: "conv_one_eltwise"
	top: "conv_2"
	param {
		lr_mult: 1
		decay_mult: 1
	}
	param {
		lr_mult: 2
		decay_mult: 0
	}
	convolution_param {
		num_output: 128
		kernel_size: 3
		stride: 2
		pad: 1
		weight_filler {
			type: "xavier"
		}
		bias_filler {
			type: "constant"
			value: 0
		}
	}
}
layer {
	name: "conv_2/bn"
	type: "BatchNorm"
	bottom: "conv_2"
	top: "conv_2"
	param {
		lr_mult: 0
		decay_mult: 0
	}
	param {
		lr_mult: 0
		decay_mult: 0
	}
	param {
		lr_mult: 0
		decay_mult: 0
	}
}
layer {
	name: "conv_2/scale"
	type: "Scale"
	bottom: "conv_2"
	top: "conv_2"
	param {
		lr_mult: 1.0
		decay_mult: 0.0
	}
	param {
		lr_mult: 2.0
		decay_mult: 0.0
	}
	scale_param {
		filler {
			value: 1
		}
		bias_term: true
		bias_filler {
			value: 0
		}
	}
}


######################RESNET#########################
layer {
	name: "conv_2_2"
	type: "Convolution"
	bottom: "conv_2"
	top: "conv_2_2"
	param {
		lr_mult: 1
		decay_mult: 1
	}
	param {
		lr_mult: 2
		decay_mult: 0
	}
	convolution_param {
		num_output: 128
		kernel_size: 3
		stride: 1
		pad: 1
		weight_filler {
			type: "xavier"
		}
		bias_filler {
			type: "constant"
			value: 0
		}
	}
}
layer {
	name: "conv_2_2/bn"
	type: "BatchNorm"
	bottom: "conv_2_2"
	top: "conv_2_2"
	param {
		lr_mult: 0
		decay_mult: 0
	}
	param {
		lr_mult: 0
		decay_mult: 0
	}
	param {
		lr_mult: 0
		decay_mult: 0
	}
}
layer {
	name: "conv_2_2/scale"
	type: "Scale"
	bottom: "conv_2_2"
	top: "conv_2_2"
	param {
		lr_mult: 1.0
		decay_mult: 0.0
	}
	param {
		lr_mult: 2.0
		decay_mult: 0.0
	}
	scale_param {
		filler {
			value: 1
		}
		bias_term: true
		bias_filler {
			value: 0
		}
	}
}

layer{
	name: "conv_two_eltwise"
	type: "Eltwise"
	bottom: "conv_2_2"
	bottom: "conv_2"
	top: "conv_two_eltwise"
	eltwise_param {
		operation: SUM
	}
}
layer {
	name: "conv_two_eltwise/relu"
	type: "PReLU"
	bottom: "conv_two_eltwise"
	top: "conv_two_eltwise"
}
###
layer {
	name: "conv_2_4"
	type: "Convolution"
	bottom: "conv_two_eltwise"
	top: "conv_2_4"
	param {
		lr_mult: 1
		decay_mult: 1
	}
	param {
		lr_mult: 2
		decay_mult: 0
	}
	convolution_param {
		num_output: 256
		kernel_size: 3
		stride: 2
		pad: 1
		weight_filler {
			type: "xavier"
		}
		bias_filler {
			type: "constant"
			value: 0
		}
	}
}

layer {
	name: "conv_2_4/bn"
	type: "BatchNorm"
	bottom: "conv_2_4"
	top: "conv_2_4"
	param {
		lr_mult: 0
		decay_mult: 0
	}
	param {
		lr_mult: 0
		decay_mult: 0
	}
	param {
		lr_mult: 0
		decay_mult: 0
	}
}
layer {
	name: "conv_2_4/scale"
	type: "Scale"
	bottom: "conv_2_4"
	top: "conv_2_4"
	param {
		lr_mult: 1.0
		decay_mult: 0.0
	}
	param {
		lr_mult: 2.0
		decay_mult: 0.0
	}
	scale_param {
		filler {
			value: 1
		}
		bias_term: true
		bias_filler {
			value: 0
		}
	}
}

###
layer {
	name: "conv_3_2"
	type: "Convolution"
	bottom: "conv_2_4"
	top: "conv_3_2"
	param {
		lr_mult: 1
		decay_mult: 1
	}
	param {
	lr_mult: 2
	decay_mult: 1
	}
	convolution_param {
		num_output: 256
		kernel_size: 3
		stride: 1
		pad: 1
		weight_filler {
			type: "xavier"
		}
		bias_filler {
			type: "constant"
			value: 0
		}
	}
}
layer {
	name: "conv_3_2/bn"
	type: "BatchNorm"
	bottom: "conv_3_2"
	top: "conv_3_2"
	param {
		lr_mult: 0
		decay_mult: 0
	}
	param {
		lr_mult: 0
		decay_mult: 0
	}
	param {
		lr_mult: 0
		decay_mult: 0
	}
}
layer {
	name: "conv_3_2/scale"
	type: "Scale"
	bottom: "conv_3_2"
	top: "conv_3_2"
	param {
		lr_mult: 1.0
		decay_mult: 0.0
	}
	param {
		lr_mult: 2.0
		decay_mult: 0.0
	}
	scale_param {
		filler {
			value: 1
		}
		bias_term: true
		bias_filler {
			value: 0
		}
	}
}
layer {
	name: "conv_three_eltwise"
	type: "Eltwise"
	bottom: "conv_3_2"
	bottom: "conv_2_4"
	top: "conv_three_eltwise"
	eltwise_param {
	operation: SUM
	}
}
layer {
	name: "conv_three_eltwise/relu"
	type: "PReLU"
	bottom: "conv_three_eltwise"
	top: "conv_three_eltwise"
}
layer {
  name: "inception_resnet_v2_a3_1x1"
  type: "Convolution"
  bottom: "conv_three_eltwise"
  top: "inception_resnet_v2_a3_1x1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_resnet_v2_a3_1x1_bn"
  type: "BatchNorm"
  bottom: "inception_resnet_v2_a3_1x1"
  top: "inception_resnet_v2_a3_1x1"
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
	batch_norm_param {
        use_global_stats: true
        moving_average_fraction: 0.95
	}
}
layer {
  name: "inception_resnet_v2_a3_1x1_scale"
  type: "Scale"
  bottom: "inception_resnet_v2_a3_1x1"
  top: "inception_resnet_v2_a3_1x1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "inception_resnet_v2_a3_1x1_relu"
  type: "PReLU"
  bottom: "inception_resnet_v2_a3_1x1"
  top: "inception_resnet_v2_a3_1x1"
}
layer {
  name: "inception_resnet_v2_a3_3x3_reduce"
  type: "Convolution"
  bottom: "conv_three_eltwise"
  top: "inception_resnet_v2_a3_3x3_reduce"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_resnet_v2_a3_3x3_reduce_bn"
  type: "BatchNorm"
  bottom: "inception_resnet_v2_a3_3x3_reduce"
  top: "inception_resnet_v2_a3_3x3_reduce"
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
	batch_norm_param {
        use_global_stats: true
        moving_average_fraction: 0.95
	}
}
layer {
  name: "inception_resnet_v2_a3_3x3_reduce_scale"
  type: "Scale"
  bottom: "inception_resnet_v2_a3_3x3_reduce"
  top: "inception_resnet_v2_a3_3x3_reduce"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "inception_resnet_v2_a3_3x3_reduce_relu"
  type: "PReLU"
  bottom: "inception_resnet_v2_a3_3x3_reduce"
  top: "inception_resnet_v2_a3_3x3_reduce"
}
layer {
  name: "inception_resnet_v2_a3_3x3"
  type: "Convolution"
  bottom: "inception_resnet_v2_a3_3x3_reduce"
  top: "inception_resnet_v2_a3_3x3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_resnet_v2_a3_3x3_bn"
  type: "BatchNorm"
  bottom: "inception_resnet_v2_a3_3x3"
  top: "inception_resnet_v2_a3_3x3"
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
	batch_norm_param {
        use_global_stats: true
        moving_average_fraction: 0.95
	}
}
layer {
  name: "inception_resnet_v2_a3_3x3_scale"
  type: "Scale"
  bottom: "inception_resnet_v2_a3_3x3"
  top: "inception_resnet_v2_a3_3x3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "inception_resnet_v2_a3_3x3_relu"
  type: "PReLU"
  bottom: "inception_resnet_v2_a3_3x3"
  top: "inception_resnet_v2_a3_3x3"
}
layer {
  name: "inception_resnet_v2_a3_3x3_2_reduce"
  type: "Convolution"
  bottom: "conv_three_eltwise"
  top: "inception_resnet_v2_a3_3x3_2_reduce"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_resnet_v2_a3_3x3_2_reduce_bn"
  type: "BatchNorm"
  bottom: "inception_resnet_v2_a3_3x3_2_reduce"
  top: "inception_resnet_v2_a3_3x3_2_reduce"
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
	batch_norm_param {
        use_global_stats: true
        moving_average_fraction: 0.95
	}
}
layer {
  name: "inception_resnet_v2_a3_3x3_2_reduce_scale"
  type: "Scale"
  bottom: "inception_resnet_v2_a3_3x3_2_reduce"
  top: "inception_resnet_v2_a3_3x3_2_reduce"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "inception_resnet_v2_a3_3x3_2_reduce_relu"
  type: "PReLU"
  bottom: "inception_resnet_v2_a3_3x3_2_reduce"
  top: "inception_resnet_v2_a3_3x3_2_reduce"
}
layer {
  name: "inception_resnet_v2_a3_3x3_2"
  type: "Convolution"
  bottom: "inception_resnet_v2_a3_3x3_2_reduce"
  top: "inception_resnet_v2_a3_3x3_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 48
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_resnet_v2_a3_3x3_2_bn"
  type: "BatchNorm"
  bottom: "inception_resnet_v2_a3_3x3_2"
  top: "inception_resnet_v2_a3_3x3_2"
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
	batch_norm_param {
        use_global_stats: true
        moving_average_fraction: 0.95
	}
}
layer {
  name: "inception_resnet_v2_a3_3x3_2_scale"
  type: "Scale"
  bottom: "inception_resnet_v2_a3_3x3_2"
  top: "inception_resnet_v2_a3_3x3_2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "inception_resnet_v2_a3_3x3_2_relu"
  type: "PReLU"
  bottom: "inception_resnet_v2_a3_3x3_2"
  top: "inception_resnet_v2_a3_3x3_2"
}
layer {
  name: "inception_resnet_v2_a3_3x3_3"
  type: "Convolution"
  bottom: "inception_resnet_v2_a3_3x3_2"
  top: "inception_resnet_v2_a3_3x3_3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_resnet_v2_a3_3x3_3_bn"
  type: "BatchNorm"
  bottom: "inception_resnet_v2_a3_3x3_3"
  top: "inception_resnet_v2_a3_3x3_3"
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
	batch_norm_param {
        use_global_stats: true
        moving_average_fraction: 0.95
	}
}
layer {
  name: "inception_resnet_v2_a3_3x3_3_scale"
  type: "Scale"
  bottom: "inception_resnet_v2_a3_3x3_3"
  top: "inception_resnet_v2_a3_3x3_3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "inception_resnet_v2_a3_3x3_3_relu"
  type: "PReLU"
  bottom: "inception_resnet_v2_a3_3x3_3"
  top: "inception_resnet_v2_a3_3x3_3"
}
layer {
  name: "inception_resnet_v2_a3_concat"
  type: "Concat"
  bottom: "inception_resnet_v2_a3_1x1"
  bottom: "inception_resnet_v2_a3_3x3"
  bottom: "inception_resnet_v2_a3_3x3_3"
  top: "inception_resnet_v2_a3_concat"
}
layer {
  name: "inception_resnet_v2_a3_up"
  type: "Convolution"
  bottom: "inception_resnet_v2_a3_concat"
  top: "inception_resnet_v2_a3_up"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 320
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_resnet_v2_a3_up_bn"
  type: "BatchNorm"
  bottom: "inception_resnet_v2_a3_up"
  top: "inception_resnet_v2_a3_up"
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
	batch_norm_param {
        use_global_stats: true
        moving_average_fraction: 0.95
	}
}
layer {
  name: "inception_resnet_v2_a3_up_scale"
  type: "Scale"
  bottom: "inception_resnet_v2_a3_up"
  top: "inception_resnet_v2_a3_up"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "inception_resnet_v2_a3_up_top"
  type: "Convolution"
  bottom: "conv_three_eltwise"
  top: "inception_resnet_v2_a3_up_top"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 320
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_resnet_v2_a3_up_top_bn"
  type: "BatchNorm"
  bottom: "inception_resnet_v2_a3_up_top"
  top: "inception_resnet_v2_a3_up_top"
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
	batch_norm_param {
        use_global_stats: true
        moving_average_fraction: 0.95
	}
}
layer {
  name: "inception_resnet_v2_a3_up_top_scale"
  type: "Scale"
  bottom: "inception_resnet_v2_a3_up_top"
  top: "inception_resnet_v2_a3_up_top"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "inception_resnet_v2_a3_residual_eltwise"
  type: "Eltwise"
  bottom: "inception_resnet_v2_a3_up_top"
  bottom: "inception_resnet_v2_a3_up"
  top: "inception_resnet_v2_a3_residual_eltwise"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "inception_resnet_v2_a3_residual_eltwise_relu"
  type: "PReLU"
  bottom: "inception_resnet_v2_a3_residual_eltwise"
  top: "inception_resnet_v2_a3_residual_eltwise"
}

layer {
  name: "reduction_a_3x3"
  type: "Convolution"
  bottom: "inception_resnet_v2_a3_residual_eltwise"
  top: "reduction_a_3x3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "reduction_a_3x3_bn"
  type: "BatchNorm"
  bottom: "reduction_a_3x3"
  top: "reduction_a_3x3"
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
	batch_norm_param {
        use_global_stats: true
        moving_average_fraction: 0.95
	}
}
layer {
  name: "reduction_a_3x3_scale"
  type: "Scale"
  bottom: "reduction_a_3x3"
  top: "reduction_a_3x3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "reduction_a_3x3_relu"
  type: "PReLU"
  bottom: "reduction_a_3x3"
  top: "reduction_a_3x3"
}
layer {
  name: "reduction_a_3x3_2_reduce"
  type: "Convolution"
  bottom: "inception_resnet_v2_a3_residual_eltwise"
  top: "reduction_a_3x3_2_reduce"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "reduction_a_3x3_2_reduce_bn"
  type: "BatchNorm"
  bottom: "reduction_a_3x3_2_reduce"
  top: "reduction_a_3x3_2_reduce"
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
	batch_norm_param {
        use_global_stats: true
        moving_average_fraction: 0.95
	}
}
layer {
  name: "reduction_a_3x3_2_reduce_scale"
  type: "Scale"
  bottom: "reduction_a_3x3_2_reduce"
  top: "reduction_a_3x3_2_reduce"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "reduction_a_3x3_2_reduce_relu"
  type: "PReLU"
  bottom: "reduction_a_3x3_2_reduce"
  top: "reduction_a_3x3_2_reduce"
}
layer {
  name: "reduction_a_3x3_2"
  type: "Convolution"
  bottom: "reduction_a_3x3_2_reduce"
  top: "reduction_a_3x3_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "reduction_a_3x3_2_bn"
  type: "BatchNorm"
  bottom: "reduction_a_3x3_2"
  top: "reduction_a_3x3_2"
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
	batch_norm_param {
        use_global_stats: true
        moving_average_fraction: 0.95
	}
}
layer {
  name: "reduction_a_3x3_2_scale"
  type: "Scale"
  bottom: "reduction_a_3x3_2"
  top: "reduction_a_3x3_2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "reduction_a_3x3_2_relu"
  type: "PReLU"
  bottom: "reduction_a_3x3_2"
  top: "reduction_a_3x3_2"
}
layer {
  name: "reduction_a_3x3_3"
  type: "Convolution"
  bottom: "reduction_a_3x3_2"
  top: "reduction_a_3x3_3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "reduction_a_3x3_3_bn"
  type: "BatchNorm"
  bottom: "reduction_a_3x3_3"
  top: "reduction_a_3x3_3"
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
	batch_norm_param {
        use_global_stats: true
        moving_average_fraction: 0.95
	}
}
layer {
  name: "reduction_a_3x3_3_scale"
  type: "Scale"
  bottom: "reduction_a_3x3_3"
  top: "reduction_a_3x3_3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "reduction_a_3x3_3_relu"
  type: "PReLU"
  bottom: "reduction_a_3x3_3"
  top: "reduction_a_3x3_3"
}
layer {
  name: "reduction_a_pool"
  type: "Pooling"
  bottom: "inception_resnet_v2_a3_residual_eltwise"
  top: "reduction_a_pool"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "reduction_a_concat"
  type: "Concat"
  bottom: "reduction_a_3x3"
  bottom: "reduction_a_3x3_3"
  bottom: "reduction_a_pool"
  top: "reduction_a_concat"
}
layer {
  name: "inception_resnet_v2_b1_1x1"
  type: "Convolution"
  bottom: "reduction_a_concat"
  top: "inception_resnet_v2_b1_1x1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 192
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_resnet_v2_b1_1x1_bn"
  type: "BatchNorm"
  bottom: "inception_resnet_v2_b1_1x1"
  top: "inception_resnet_v2_b1_1x1"
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
	batch_norm_param {
        use_global_stats: true
        moving_average_fraction: 0.95
	}
}
layer {
  name: "inception_resnet_v2_b1_1x1_scale"
  type: "Scale"
  bottom: "inception_resnet_v2_b1_1x1"
  top: "inception_resnet_v2_b1_1x1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "inception_resnet_v2_b1_1x1_relu"
  type: "PReLU"
  bottom: "inception_resnet_v2_b1_1x1"
  top: "inception_resnet_v2_b1_1x1"
}
layer {
  name: "inception_resnet_v2_b1_1x7_reduce"
  type: "Convolution"
  bottom: "reduction_a_concat"
  top: "inception_resnet_v2_b1_1x7_reduce"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_resnet_v2_b1_1x7_reduce_bn"
  type: "BatchNorm"
  bottom: "inception_resnet_v2_b1_1x7_reduce"
  top: "inception_resnet_v2_b1_1x7_reduce"
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
	batch_norm_param {
        use_global_stats: true
        moving_average_fraction: 0.95
	}
}
layer {
  name: "inception_resnet_v2_b1_1x7_reduce_scale"
  type: "Scale"
  bottom: "inception_resnet_v2_b1_1x7_reduce"
  top: "inception_resnet_v2_b1_1x7_reduce"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "inception_resnet_v2_b1_1x7_reduce_relu"
  type: "PReLU"
  bottom: "inception_resnet_v2_b1_1x7_reduce"
  top: "inception_resnet_v2_b1_1x7_reduce"
}
layer {
  name: "inception_resnet_v2_b1_1x7"
  type: "Convolution"
  bottom: "inception_resnet_v2_b1_1x7_reduce"
  top: "inception_resnet_v2_b1_1x7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 160
    stride: 1
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
    pad_h: 0
    pad_w: 3
    kernel_h: 1
    kernel_w: 7
  }
}
layer {
  name: "inception_resnet_v2_b1_1x7_bn"
  type: "BatchNorm"
  bottom: "inception_resnet_v2_b1_1x7"
  top: "inception_resnet_v2_b1_1x7"
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
	batch_norm_param {
        use_global_stats: true
        moving_average_fraction: 0.95
	}
}
layer {
  name: "inception_resnet_v2_b1_1x7_scale"
  type: "Scale"
  bottom: "inception_resnet_v2_b1_1x7"
  top: "inception_resnet_v2_b1_1x7"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "inception_resnet_v2_b1_1x7_relu"
  type: "PReLU"
  bottom: "inception_resnet_v2_b1_1x7"
  top: "inception_resnet_v2_b1_1x7"
}
layer {
  name: "inception_resnet_v2_b1_7x1"
  type: "Convolution"
  bottom: "inception_resnet_v2_b1_1x7"
  top: "inception_resnet_v2_b1_7x1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 192
    stride: 1
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
    pad_h: 3
    pad_w: 0
    kernel_h: 7
    kernel_w: 1
  }
}
layer {
  name: "inception_resnet_v2_b1_7x1_bn"
  type: "BatchNorm"
  bottom: "inception_resnet_v2_b1_7x1"
  top: "inception_resnet_v2_b1_7x1"
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
	batch_norm_param {
        use_global_stats: true
        moving_average_fraction: 0.95
	}
}
layer {
  name: "inception_resnet_v2_b1_7x1_scale"
  type: "Scale"
  bottom: "inception_resnet_v2_b1_7x1"
  top: "inception_resnet_v2_b1_7x1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "inception_resnet_v2_b1_7x1_relu"
  type: "PReLU"
  bottom: "inception_resnet_v2_b1_7x1"
  top: "inception_resnet_v2_b1_7x1"
}
layer {
  name: "inception_resnet_v2_b1_concat"
  type: "Concat"
  bottom: "inception_resnet_v2_b1_1x1"
  bottom: "inception_resnet_v2_b1_7x1"
  top: "inception_resnet_v2_b1_concat"
}
layer {
  name: "inception_resnet_v2_b1_up"
  type: "Convolution"
  bottom: "inception_resnet_v2_b1_concat"
  top: "inception_resnet_v2_b1_up"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 1088
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_resnet_v2_b1_up_bn"
  type: "BatchNorm"
  bottom: "inception_resnet_v2_b1_up"
  top: "inception_resnet_v2_b1_up"
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
	batch_norm_param {
        use_global_stats: true
        moving_average_fraction: 0.95
	}
}
layer {
  name: "inception_resnet_v2_b1_up_scale"
  type: "Scale"
  bottom: "inception_resnet_v2_b1_up"
  top: "inception_resnet_v2_b1_up"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "inception_resnet_v2_b1_residual_eltwise"
  type: "Eltwise"
  bottom: "reduction_a_concat"
  bottom: "inception_resnet_v2_b1_up"
  top: "inception_resnet_v2_b1_residual_eltwise"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "inception_resnet_v2_b1_residual_eltwise_relu"
  type: "PReLU"
  bottom: "inception_resnet_v2_b1_residual_eltwise"
  top: "inception_resnet_v2_b1_residual_eltwise"
}
layer {
  name: "inception_resnet_v2_b2_1x1"
  type: "Convolution"
  bottom: "inception_resnet_v2_b1_residual_eltwise"
  top: "inception_resnet_v2_b2_1x1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 192
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_resnet_v2_b2_1x1_bn"
  type: "BatchNorm"
  bottom: "inception_resnet_v2_b2_1x1"
  top: "inception_resnet_v2_b2_1x1"
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
	batch_norm_param {
        use_global_stats: true
        moving_average_fraction: 0.95
	}
}
layer {
  name: "inception_resnet_v2_b2_1x1_scale"
  type: "Scale"
  bottom: "inception_resnet_v2_b2_1x1"
  top: "inception_resnet_v2_b2_1x1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "inception_resnet_v2_b2_1x1_relu"
  type: "PReLU"
  bottom: "inception_resnet_v2_b2_1x1"
  top: "inception_resnet_v2_b2_1x1"
}
layer {
  name: "inception_resnet_v2_b2_1x7_reduce"
  type: "Convolution"
  bottom: "inception_resnet_v2_b1_residual_eltwise"
  top: "inception_resnet_v2_b2_1x7_reduce"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_resnet_v2_b2_1x7_reduce_bn"
  type: "BatchNorm"
  bottom: "inception_resnet_v2_b2_1x7_reduce"
  top: "inception_resnet_v2_b2_1x7_reduce"
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
	batch_norm_param {
        use_global_stats: true
        moving_average_fraction: 0.95
	}
}
layer {
  name: "inception_resnet_v2_b2_1x7_reduce_scale"
  type: "Scale"
  bottom: "inception_resnet_v2_b2_1x7_reduce"
  top: "inception_resnet_v2_b2_1x7_reduce"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "inception_resnet_v2_b2_1x7_reduce_relu"
  type: "PReLU"
  bottom: "inception_resnet_v2_b2_1x7_reduce"
  top: "inception_resnet_v2_b2_1x7_reduce"
}
layer {
  name: "inception_resnet_v2_b2_1x7"
  type: "Convolution"
  bottom: "inception_resnet_v2_b2_1x7_reduce"
  top: "inception_resnet_v2_b2_1x7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 160
    stride: 1
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
    pad_h: 0
    pad_w: 3
    kernel_h: 1
    kernel_w: 7
  }
}
layer {
  name: "inception_resnet_v2_b2_1x7_bn"
  type: "BatchNorm"
  bottom: "inception_resnet_v2_b2_1x7"
  top: "inception_resnet_v2_b2_1x7"
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
	batch_norm_param {
        use_global_stats: true
        moving_average_fraction: 0.95
	}
}
layer {
  name: "inception_resnet_v2_b2_1x7_scale"
  type: "Scale"
  bottom: "inception_resnet_v2_b2_1x7"
  top: "inception_resnet_v2_b2_1x7"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "inception_resnet_v2_b2_1x7_relu"
  type: "PReLU"
  bottom: "inception_resnet_v2_b2_1x7"
  top: "inception_resnet_v2_b2_1x7"
}
layer {
  name: "inception_resnet_v2_b2_7x1"
  type: "Convolution"
  bottom: "inception_resnet_v2_b2_1x7"
  top: "inception_resnet_v2_b2_7x1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 192
    stride: 1
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
    pad_h: 3
    pad_w: 0
    kernel_h: 7
    kernel_w: 1
  }
}
layer {
  name: "inception_resnet_v2_b2_7x1_bn"
  type: "BatchNorm"
  bottom: "inception_resnet_v2_b2_7x1"
  top: "inception_resnet_v2_b2_7x1"
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
	batch_norm_param {
        use_global_stats: true
        moving_average_fraction: 0.95
	}
}
layer {
  name: "inception_resnet_v2_b2_7x1_scale"
  type: "Scale"
  bottom: "inception_resnet_v2_b2_7x1"
  top: "inception_resnet_v2_b2_7x1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "inception_resnet_v2_b2_7x1_relu"
  type: "PReLU"
  bottom: "inception_resnet_v2_b2_7x1"
  top: "inception_resnet_v2_b2_7x1"
}
layer {
  name: "inception_resnet_v2_b2_concat"
  type: "Concat"
  bottom: "inception_resnet_v2_b2_1x1"
  bottom: "inception_resnet_v2_b2_7x1"
  top: "inception_resnet_v2_b2_concat"
}
layer {
  name: "inception_resnet_v2_b2_up"
  type: "Convolution"
  bottom: "inception_resnet_v2_b2_concat"
  top: "inception_resnet_v2_b2_up"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 1088
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_resnet_v2_b2_up_bn"
  type: "BatchNorm"
  bottom: "inception_resnet_v2_b2_up"
  top: "inception_resnet_v2_b2_up"
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
	batch_norm_param {
        use_global_stats: true
        moving_average_fraction: 0.95
	}
}
layer {
  name: "inception_resnet_v2_b2_up_scale"
  type: "Scale"
  bottom: "inception_resnet_v2_b2_up"
  top: "inception_resnet_v2_b2_up"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "inception_resnet_v2_b2_residual_eltwise"
  type: "Eltwise"
  bottom: "inception_resnet_v2_b1_residual_eltwise"
  bottom: "inception_resnet_v2_b2_up"
  top: "inception_resnet_v2_b2_residual_eltwise"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "inception_resnet_v2_b2_residual_eltwise_relu"
  type: "PReLU"
  bottom: "inception_resnet_v2_b2_residual_eltwise"
  top: "inception_resnet_v2_b2_residual_eltwise"
}
layer {
  name: "inception_resnet_v2_c1_1x1"
  type: "Convolution"
  bottom: "inception_resnet_v2_b2_residual_eltwise"
  top: "inception_resnet_v2_c1_1x1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 192
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_resnet_v2_c1_1x1_bn"
  type: "BatchNorm"
  bottom: "inception_resnet_v2_c1_1x1"
  top: "inception_resnet_v2_c1_1x1"
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
	batch_norm_param {
        use_global_stats: true
        moving_average_fraction: 0.95
	}
}
layer {
  name: "inception_resnet_v2_c1_1x1_scale"
  type: "Scale"
  bottom: "inception_resnet_v2_c1_1x1"
  top: "inception_resnet_v2_c1_1x1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "inception_resnet_v2_c1_1x1_relu"
  type: "PReLU"
  bottom: "inception_resnet_v2_c1_1x1"
  top: "inception_resnet_v2_c1_1x1"
}
layer {
  name: "inception_resnet_v2_c1_1x3_reduce"
  type: "Convolution"
  bottom: "inception_resnet_v2_b2_residual_eltwise"
  top: "inception_resnet_v2_c1_1x3_reduce"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 192
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_resnet_v2_c1_1x3_reduce_bn"
  type: "BatchNorm"
  bottom: "inception_resnet_v2_c1_1x3_reduce"
  top: "inception_resnet_v2_c1_1x3_reduce"
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
	batch_norm_param {
        use_global_stats: true
        moving_average_fraction: 0.95
	}
}
layer {
  name: "inception_resnet_v2_c1_1x3_reduce_scale"
  type: "Scale"
  bottom: "inception_resnet_v2_c1_1x3_reduce"
  top: "inception_resnet_v2_c1_1x3_reduce"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "inception_resnet_v2_c1_1x3_reduce_relu"
  type: "PReLU"
  bottom: "inception_resnet_v2_c1_1x3_reduce"
  top: "inception_resnet_v2_c1_1x3_reduce"
}
layer {
  name: "inception_resnet_v2_c1_1x3"
  type: "Convolution"
  bottom: "inception_resnet_v2_c1_1x3_reduce"
  top: "inception_resnet_v2_c1_1x3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 224
    stride: 1
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
    pad_h: 0
    pad_w: 1
    kernel_h: 1
    kernel_w: 3
  }
}
layer {
  name: "inception_resnet_v2_c1_1x3_bn"
  type: "BatchNorm"
  bottom: "inception_resnet_v2_c1_1x3"
  top: "inception_resnet_v2_c1_1x3"
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
	batch_norm_param {
        use_global_stats: true
        moving_average_fraction: 0.95
	}
}
layer {
  name: "inception_resnet_v2_c1_1x3_scale"
  type: "Scale"
  bottom: "inception_resnet_v2_c1_1x3"
  top: "inception_resnet_v2_c1_1x3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "inception_resnet_v2_c1_1x3_relu"
  type: "PReLU"
  bottom: "inception_resnet_v2_c1_1x3"
  top: "inception_resnet_v2_c1_1x3"
}
layer {
  name: "inception_resnet_v2_c1_3x1"
  type: "Convolution"
  bottom: "inception_resnet_v2_c1_1x3"
  top: "inception_resnet_v2_c1_3x1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    stride: 1
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
    pad_h: 1
    pad_w: 0
    kernel_h: 3
    kernel_w: 1
  }
}
layer {
  name: "inception_resnet_v2_c1_3x1_bn"
  type: "BatchNorm"
  bottom: "inception_resnet_v2_c1_3x1"
  top: "inception_resnet_v2_c1_3x1"
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
	batch_norm_param {
        use_global_stats: true
        moving_average_fraction: 0.95
	}
}
layer {
  name: "inception_resnet_v2_c1_3x1_scale"
  type: "Scale"
  bottom: "inception_resnet_v2_c1_3x1"
  top: "inception_resnet_v2_c1_3x1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "inception_resnet_v2_c1_3x1_relu"
  type: "PReLU"
  bottom: "inception_resnet_v2_c1_3x1"
  top: "inception_resnet_v2_c1_3x1"
}
layer {
  name: "inception_resnet_v2_c1_concat"
  type: "Concat"
  bottom: "inception_resnet_v2_c1_1x1"
  bottom: "inception_resnet_v2_c1_3x1"
  top: "inception_resnet_v2_c1_concat"
}
layer {
  name: "inception_resnet_v2_c1_up"
  type: "Convolution"
  bottom: "inception_resnet_v2_c1_concat"
  top: "inception_resnet_v2_c1_up"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 1088
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_resnet_v2_c1_up_bn"
  type: "BatchNorm"
  bottom: "inception_resnet_v2_c1_up"
  top: "inception_resnet_v2_c1_up"
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
	batch_norm_param {
        use_global_stats: true
        moving_average_fraction: 0.95
	}
}
layer {
  name: "inception_resnet_v2_c1_up_scale"
  type: "Scale"
  bottom: "inception_resnet_v2_c1_up"
  top: "inception_resnet_v2_c1_up"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "inception_resnet_v2_c1_residual_eltwise"
  type: "Eltwise"
  bottom: "inception_resnet_v2_b2_residual_eltwise"
  bottom: "inception_resnet_v2_c1_up"
  top: "inception_resnet_v2_c1_residual_eltwise"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "reduction_b_3x3_reduce"
  type: "Convolution"
  bottom: "inception_resnet_v2_c1_residual_eltwise"
  top: "reduction_b_3x3_reduce"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "reduction_b_3x3_reduce_bn"
  type: "BatchNorm"
  bottom: "reduction_b_3x3_reduce"
  top: "reduction_b_3x3_reduce"
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
	batch_norm_param {
        use_global_stats: true
        moving_average_fraction: 0.95
	}
}
layer {
  name: "reduction_b_3x3_reduce_scale"
  type: "Scale"
  bottom: "reduction_b_3x3_reduce"
  top: "reduction_b_3x3_reduce"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "reduction_b_3x3_reduce_relu"
  type: "PReLU"
  bottom: "reduction_b_3x3_reduce"
  top: "reduction_b_3x3_reduce"
}
layer {
  name: "reduction_b_3x3"
  type: "Convolution"
  bottom: "reduction_b_3x3_reduce"
  top: "reduction_b_3x3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 0
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "reduction_b_3x3_bn"
  type: "BatchNorm"
  bottom: "reduction_b_3x3"
  top: "reduction_b_3x3"
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
	batch_norm_param {
        use_global_stats: true
        moving_average_fraction: 0.95
	}
}
layer {
  name: "reduction_b_3x3_scale"
  type: "Scale"
  bottom: "reduction_b_3x3"
  top: "reduction_b_3x3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "reduction_b_3x3_relu"
  type: "PReLU"
  bottom: "reduction_b_3x3"
  top: "reduction_b_3x3"
}
layer {
  name: "reduction_b_3x3_2_reduce"
  type: "Convolution"
  bottom: "inception_resnet_v2_c1_residual_eltwise"
  top: "reduction_b_3x3_2_reduce"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "reduction_b_3x3_2_reduce_bn"
  type: "BatchNorm"
  bottom: "reduction_b_3x3_2_reduce"
  top: "reduction_b_3x3_2_reduce"
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
	batch_norm_param {
        use_global_stats: true
        moving_average_fraction: 0.95
	}
}
layer {
  name: "reduction_b_3x3_2_reduce_scale"
  type: "Scale"
  bottom: "reduction_b_3x3_2_reduce"
  top: "reduction_b_3x3_2_reduce"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "reduction_b_3x3_2_reduce_relu"
  type: "PReLU"
  bottom: "reduction_b_3x3_2_reduce"
  top: "reduction_b_3x3_2_reduce"
}
layer {
  name: "reduction_b_3x3_2"
  type: "Convolution"
  bottom: "reduction_b_3x3_2_reduce"
  top: "reduction_b_3x3_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 288
    pad: 0
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "reduction_b_3x3_2_bn"
  type: "BatchNorm"
  bottom: "reduction_b_3x3_2"
  top: "reduction_b_3x3_2"
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
	batch_norm_param {
        use_global_stats: true
        moving_average_fraction: 0.95
	}
}
layer {
  name: "reduction_b_3x3_2_scale"
  type: "Scale"
  bottom: "reduction_b_3x3_2"
  top: "reduction_b_3x3_2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "reduction_b_3x3_2_relu"
  type: "PReLU"
  bottom: "reduction_b_3x3_2"
  top: "reduction_b_3x3_2"
}
layer {
  name: "reduction_b_3x3_3_reduce"
  type: "Convolution"
  bottom: "inception_resnet_v2_c1_residual_eltwise"
  top: "reduction_b_3x3_3_reduce"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "reduction_b_3x3_3_reduce_bn"
  type: "BatchNorm"
  bottom: "reduction_b_3x3_3_reduce"
  top: "reduction_b_3x3_3_reduce"
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
	batch_norm_param {
        use_global_stats: true
        moving_average_fraction: 0.95
	}
}
layer {
  name: "reduction_b_3x3_3_reduce_scale"
  type: "Scale"
  bottom: "reduction_b_3x3_3_reduce"
  top: "reduction_b_3x3_3_reduce"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "reduction_b_3x3_3_reduce_relu"
  type: "PReLU"
  bottom: "reduction_b_3x3_3_reduce"
  top: "reduction_b_3x3_3_reduce"
}
layer {
  name: "reduction_b_3x3_3"
  type: "Convolution"
  bottom: "reduction_b_3x3_3_reduce"
  top: "reduction_b_3x3_3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 288
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "reduction_b_3x3_3_bn"
  type: "BatchNorm"
  bottom: "reduction_b_3x3_3"
  top: "reduction_b_3x3_3"
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
	batch_norm_param {
        use_global_stats: true
        moving_average_fraction: 0.95
	}
}
layer {
  name: "reduction_b_3x3_3_scale"
  type: "Scale"
  bottom: "reduction_b_3x3_3"
  top: "reduction_b_3x3_3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "reduction_b_3x3_3_relu"
  type: "PReLU"
  bottom: "reduction_b_3x3_3"
  top: "reduction_b_3x3_3"
}
layer {
  name: "reduction_b_3x3_4"
  type: "Convolution"
  bottom: "reduction_b_3x3_3"
  top: "reduction_b_3x3_4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 320
    pad: 0
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "reduction_b_3x3_4_bn"
  type: "BatchNorm"
  bottom: "reduction_b_3x3_4"
  top: "reduction_b_3x3_4"
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
	batch_norm_param {
        use_global_stats: true
        moving_average_fraction: 0.95
	}
}
layer {
  name: "reduction_b_3x3_4_scale"
  type: "Scale"
  bottom: "reduction_b_3x3_4"
  top: "reduction_b_3x3_4"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "reduction_b_3x3_4_relu"
  type: "PReLU"
  bottom: "reduction_b_3x3_4"
  top: "reduction_b_3x3_4"
}
layer {
  name: "reduction_b_concat"
  type: "Concat"
  bottom: "reduction_b_3x3"
  bottom: "reduction_b_3x3_2"
  bottom: "reduction_b_3x3_4"
  top: "reduction_b_concat"
}
layer {
	name: "conv6_1x1"
	type: "Convolution"
	bottom: "reduction_b_concat"
	top: "conv6_1x1"
	param {
		lr_mult: 1
		decay_mult: 1
	}
	param {
		lr_mult: 2
		decay_mult: 0
	}
	convolution_param {
		num_output: 512
		pad: 0
		kernel_size: 3
		stride: 1
		weight_filler {
			type: "xavier"
			std: 0.01
		}
		bias_filler {
			type: "constant"
			value: 0.2
		}
	}
}
layer {
	name: "conv6_1x1_bn"
	type: "BatchNorm"
	bottom: "conv6_1x1"
	top: "conv6_1x1"
	param {
		lr_mult: 0.0
		decay_mult: 0.0
	}
	param {
		lr_mult: 0.0
		decay_mult: 0.0
	}
	param {
		lr_mult: 0.0
		decay_mult: 0.0
	}
	batch_norm_param {
		use_global_stats: true
		moving_average_fraction: 0.95
	}
}
layer {
	name: "conv6_1x1_scale"
	type: "Scale"
	bottom: "conv6_1x1"
	top: "conv6_1x1"
	scale_param {
	bias_term: true
	}
}
layer {
  name: "conv6_1x1_relu"
  type: "ReLU"
  bottom: "conv6_1x1"
  top: "conv6_1x1"
}
##########################################################
layer {
	name: "fc5"
	type: "InnerProduct"
	bottom: "conv6_1x1"
	top: "fc5"
	param {
		lr_mult: 1
		decay_mult: 1
	}
	param {
		lr_mult: 2
		decay_mult: 0
	}
	inner_product_param {
		num_output: 256
		weight_filler {
			type: "xavier"
		}
		bias_filler {
			type: "constant"
			value: 0
		}
	}
}
################softmax loss##########################
layer {
	name: "lmcl_cos_l2_normalize"
	type: "InnerProduct"
	bottom: "fc5"
	top: "lmcl_cos_l2_normalize"
	param {
		lr_mult: 1
		decay_mult: 2 
	}
	inner_product_param{
		num_output: 8631
		weight_filler {
		type: "xavier"
		}
	}
}
##############cosinface loss#############
#layer {
#	name: "lmcl_cos_l2_normalize"
#	type: "CosinL2Normalize"
#	bottom: "fc5"
#	bottom: "labelIndex"
#	top: "lmcl_cos_l2_normalize"
#	param {
#		lr_mult: 1
#		decay_mult: 2 
#	}
#	cosin_loss_param {
#		margin: -0.35
#		scale: 64
#		num_output: 8631
#		cosin_filler {
#			type: "xavier"
#		}
#	}
#}
################arcface-loss#############
#layer {
#	name: "cosin_add_m"
#	type: "CosinAddm"
#	bottom: "fc5"
#	bottom: "labelIndex"
#	top: "fc6_margin"
#	cosin_add_m_param {
#		m: 0.5
#	}
#} 
#layer {
#	name: "lmcl_cos_l2_normalize"
#	type: "Scale"
#	bottom: "fc6_margin"
#	top: "lmcl_cos_l2_normalize"
#	param {
#		lr_mult: 0
#		decay_mult: 0
#	}
#	scale_param {
#		filler{
#			type: "constant"
#			value: 64
#		}
#	}
#}
layer {
	name: "softmax_loss"
	type: "SoftmaxWithLoss"
	bottom: "lmcl_cos_l2_normalize"
	bottom: "labelIndex"
	top: "softmax_loss"
	propagate_down: true
	propagate_down: false
}

############## center loss ###############
layer {
	name: "center_loss"
	type: "CenterLoss"
	bottom: "fc5"
	bottom: "labelIndex"
	top: "center_loss"
	param {
		lr_mult: 1
		decay_mult: 2 
	}
	center_loss_param {
		num_output: 8631
		center_filler {
			type: "xavier"
		}
	}
	loss_weight: 0.8
}
##############contravie loss###############
layer {
	name: "merege_pair"
	type: "Identity2Verify"
	bottom: "fc5"
	bottom: "labelIndex"
	top: "feature1"
	top: "feature2"
	top: "sim"
}

layer {
	name: "norm1"
	type: "SimpleNormalize"
	bottom: "feature1"
	top: "normfeature1"
}

layer {
	name: "norm2"
	type: "SimpleNormalize"
	bottom: "feature2"
	top: "normfeature2"
}

layer {
	name: "sim_loss"
	type: "ContrastiveLoss"
	bottom: "normfeature1"
	bottom: "normfeature2"
	bottom: "sim"
	top: "sim_loss"
	loss_weight: 0.3
	contrastive_loss_param {
		margin: 1
	}
}

#######################tripletloss############
layer {
	name: "fc5_feature"
	type: "SimpleNormalize"
	bottom: "fc5"
	top: "fc5_feature"
}
layer {
	name: "archor_pair"
	type: "SampleTriplet"
	bottom: "fc5_feature"
	bottom: "label"
	top: "archor_pair"
	propagate_down: false
	propagate_down: false
}
layer {
	name: "tripletloss"
	type: "TripletLoss"
	bottom: "fc5_feature"
	bottom: "archor_pair"
	top: "tripletloss"
	loss_weight: 1
	propagate_down: true
	propagate_down: true
}
