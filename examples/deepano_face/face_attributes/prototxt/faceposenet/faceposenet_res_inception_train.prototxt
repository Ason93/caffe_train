name: "deepano_face_posenet"
layer {
	name: "data"
	type: "facePoseData"
	top: "data"
	top: "label"
	include {
		phase: TRAIN
	}
	transform_param {
		scale: 0.007843
		mirror: false
		mean_value: 127.5
		mean_value: 127.5
		mean_value: 127.5
		resize_param {
			prob: 1.0
			resize_mode: WARP
			height: 99
			width: 99
			interp_mode: LINEAR
			interp_mode: AREA
			interp_mode: NEAREST
			interp_mode: CUBIC
			interp_mode: LANCZOS4
		}
		emit_constraint {
			emit_type: CENTER
		}
		distort_param {
			brightness_prob: 0.5
			brightness_delta: 32.0
			contrast_prob: 0.5
			contrast_lower: 0.5
			contrast_upper: 1.5
			hue_prob: 0.5
			hue_delta: 18.0
			saturation_prob: 0.5
			saturation_lower: 0.5
			saturation_upper: 1.5
			random_order_prob: 0.0
		}
		expand_param {
			prob: 0.5
			max_expand_ratio: 4.0
		}
	}
	data_param {
		source: "../../../../../dataset/facedata/umdface/lmdb/umdface_training_lmdb/"
		batch_size: 64
		backend: LMDB
	}
}

layer {
	name: "conv1_3x3_s2"
	type: "Convolution"
	bottom: "data"
	top: "conv1_3x3_s2"
	param {
		lr_mult: 1
		decay_mult: 1
	}
	param {
		lr_mult: 2
		decay_mult: 0
	}
	convolution_param {
		num_output: 32
		pad: 0
		kernel_size: 3
		stride: 2
		weight_filler {
			type: "xavier"
			std: 0.01
		}
		bias_filler {
			type: "constant"
			value: 0.0
		}
	}
}
layer {
	name: "conv1_3x3_s2_bn"
	type: "BatchNorm"
	bottom: "conv1_3x3_s2"
	top: "conv1_3x3_s2"
	param {
		lr_mult: 0.0
		decay_mult: 0.0
	}
	param {
		lr_mult: 0.0
		decay_mult: 0.0
	}
	param {
		lr_mult: 0.0
		decay_mult: 0.0
	}
	batch_norm_param {
		use_global_stats: false
		moving_average_fraction: 0.95
	}
}
layer {
	name: "conv1_3x3_s2_scale"
	type: "Scale"
	bottom: "conv1_3x3_s2"
	top: "conv1_3x3_s2"
	scale_param {
		bias_term: true
	}
}
layer {
	name: "conv1_3x3_relu"
	type: "ReLU"
	bottom: "conv1_3x3_s2"
	top: "conv1_3x3_s2"
}
layer {
	name: "conv2_3x3_s1"
	type: "Convolution"
	bottom: "conv1_3x3_s2"
	top: "conv2_3x3_s1"
	param {
		lr_mult: 1
		decay_mult: 1
	}
	param {
		lr_mult: 2
		decay_mult: 0
	}
	convolution_param {
		num_output: 32
		pad: 0
		kernel_size: 3
		stride: 1
		weight_filler {
			type: "xavier"
			std: 0.01
		}
		bias_filler {
			type: "constant"
			value: 0.2
		}
	}
}
layer {
	name: "conv2_3x3_s1_bn"
	type: "BatchNorm"
	bottom: "conv2_3x3_s1"
	top: "conv2_3x3_s1"
	param {
		lr_mult: 0.0
		decay_mult: 0.0
	}
	param {
		lr_mult: 0.0
		decay_mult: 0.0
	}
	param {
		lr_mult: 0.0
		decay_mult: 0.0
	}
	batch_norm_param {
		use_global_stats: false
		moving_average_fraction: 0.95
	}
}
layer {
	name: "conv2_3x3_s1_scale"
	type: "Scale"
	bottom: "conv2_3x3_s1"
	top: "conv2_3x3_s1"
	scale_param {
		bias_term: true
	}
	}
layer {
	name: "conv2_3x3_relu"
	type: "ReLU"
	bottom: "conv2_3x3_s1"
	top: "conv2_3x3_s1"
}
layer {
	name: "conv3_3x3_s1"
	type: "Convolution"
	bottom: "conv2_3x3_s1"
	top: "conv3_3x3_s1"
	param {
	lr_mult: 1
	decay_mult: 1
	}
	param {
	lr_mult: 2
	decay_mult: 0
	}
	convolution_param {
		num_output: 64
		pad: 0
		kernel_size: 3
		stride: 1
		weight_filler {
			type: "xavier"
			std: 0.01
		}
		bias_filler {
			type: "constant"
			value: 0.2
		}
	}
}
layer {
	name: "conv3_3x3_s1_bn"
	type: "BatchNorm"
	bottom: "conv3_3x3_s1"
	top: "conv3_3x3_s1"
	param {
		lr_mult: 0.0
		decay_mult: 0.0
	}
	param {
		lr_mult: 0.0
		decay_mult: 0.0
	}
	param {
		lr_mult: 0.0
		decay_mult: 0.0
	}
	batch_norm_param {
		use_global_stats: false
		moving_average_fraction: 0.95
	}
}
layer {
		name: "conv3_3x3_s1_scale"
		type: "Scale"
		bottom: "conv3_3x3_s1"
		top: "conv3_3x3_s1"
		scale_param {
			bias_term: true
	}
}
layer {
		name: "conv3_3x3_relu"
		type: "ReLU"
		bottom: "conv3_3x3_s1"
		top: "conv3_3x3_s1"
}

layer {
	name: "inception_conv_1_out32x1"
	type: "Convolution"
	bottom: "conv3_3x3_s1" #################
	top: "inception_conv_1_out32x1"
	param {
		lr_mult: 1
		decay_mult: 1
	}
	param {
		lr_mult: 2
		decay_mult: 1
	}
	convolution_param {
		num_output: 32
		kernel_size: 1
		stride: 1
		weight_filler {
			type: "xavier"
		}
		bias_filler {
			type: "constant"
			value: 0
		}
	}
}
layer {
	name: "inception_conv_1_out32x1/bn"
	type: "BatchNorm"
	bottom: "inception_conv_1_out32x1"
	top: "inception_conv_1_out32x1"
	param {
		lr_mult: 0
		decay_mult: 0
	}
	param {
		lr_mult: 0
		decay_mult: 0
	}
	param {
		lr_mult: 0
		decay_mult: 0
	}
	batch_norm_param {
		use_global_stats: false
		moving_average_fraction: 0.95
	}
}
layer {
	name: "inception_conv_1_out32x1/scale"
	type: "Scale"
	bottom: "inception_conv_1_out32x1"
	top: "inception_conv_1_out32x1"
	param {
		lr_mult: 1.0
		decay_mult: 0.0
	}
	param {
		lr_mult: 2.0
		decay_mult: 0.0
	}
	scale_param {
		filler {
			value: 1
		}
		bias_term: true
		bias_filler {
			value: 0
		}
	}
}
layer {
	name: "inception_conv_1_out32x1/relu"
	type: "ReLU"
	bottom: "inception_conv_1_out32x1"
	top: "inception_conv_1_out32x1"
}
layer {
	name: "inception_conv_1_out48x3"
	type: "Convolution"
	bottom: "inception_conv_1_out32x1"
	top: "inception_conv_1_out48x3"
	param {
		lr_mult: 1
		decay_mult: 1
	}
	param {
		lr_mult: 2
		decay_mult: 1
	}
	convolution_param {
		num_output: 48
		kernel_size: 3
		stride: 1
		pad: 1
		weight_filler {
		    type: "xavier"
		}
		bias_filler {
			type: "constant"
			value: 0
		}
	}
}
layer {
	name: "inception_conv_1_out48x3/bn"
	type: "BatchNorm"
	bottom: "inception_conv_1_out48x3"
	top: "inception_conv_1_out48x3"
	param {
		lr_mult: 0
		decay_mult: 0
	}
	param {
		lr_mult: 0
		decay_mult: 0
	}
	param {
		lr_mult: 0
		decay_mult: 0
	}
	batch_norm_param {
		use_global_stats: false
		moving_average_fraction: 0.95
	}
}
layer {
	name: "inception_conv_1_out48x3/scale"
	type: "Scale"
	bottom: "inception_conv_1_out48x3"
	top: "inception_conv_1_out48x3"
	param {
		lr_mult: 1.0
		decay_mult: 0.0
	}
	param {
		lr_mult: 2.0
		decay_mult: 0.0
	}
	scale_param {
		filler {
			value: 1
		}
		bias_term: true
		bias_filler {
			value: 0
		}
	}
}
layer {
	name: "inception_conv_1_out48x3/relu"
	type: "ReLU"
	bottom: "inception_conv_1_out48x3"
	top: "inception_conv_1_out48x3"
}
layer {
	name: "inception_conv_1_out64x3"
	type: "Convolution"
	bottom: "inception_conv_1_out48x3"
	top: "inception_conv_1_out64x3"
	param {
		lr_mult: 1
		decay_mult: 1
	}
	param {
		lr_mult: 2
		decay_mult: 1
	}
	convolution_param {
		num_output: 32
		kernel_size: 3
		stride: 1
		pad: 1
		weight_filler {
		    type: "xavier"
		}
		bias_filler {
			type: "constant"
			value: 0
		}
	}
}
layer {
	name: "inception_conv_1_out64x3/bn"
	type: "BatchNorm"
	bottom: "inception_conv_1_out64x3"
	top: "inception_conv_1_out64x3"
	param {
		lr_mult: 0
		decay_mult: 0
	}
	param {
		lr_mult: 0
		decay_mult: 0
	}
	param {
		lr_mult: 0
		decay_mult: 0
	}
	batch_norm_param {
		use_global_stats: false
		moving_average_fraction: 0.95
	}
}
layer {
	name: "inception_conv_1_out64x3/scale"
	type: "Scale"
	bottom: "inception_conv_1_out64x3"
	top: "inception_conv_1_out64x3"
	param {
		lr_mult: 1.0
		decay_mult: 0.0
	}
	param {
		lr_mult: 2.0
		decay_mult: 0.0
	}
	scale_param {
		filler {
			value: 1
		}
		bias_term: true
		bias_filler {
			value: 0
		}
	}
}
layer {
	name: "inception_conv_1_out64x3/relu"
	type: "ReLU"
	bottom: "inception_conv_1_out64x3"
	top: "inception_conv_1_out64x3"
}
layer {
	name: "inception_conv_2_out32x1"
	type: "Convolution"
	bottom: "conv3_3x3_s1"  #################
	top: "inception_conv_2_out32x1"
	param {
		lr_mult: 1
		decay_mult: 1
	}
	param {
		lr_mult: 2
		decay_mult: 1
	}
	convolution_param {
		num_output: 32
		kernel_size: 1
		stride: 1
		weight_filler {
		    type: "xavier"
		}
		bias_filler {
			type: "constant"
			value: 0
		}
	}
}
layer {
	name: "inception_conv_2_out32x1/bn"
	type: "BatchNorm"
	bottom: "inception_conv_2_out32x1"
	top: "inception_conv_2_out32x1"
	param {
		lr_mult: 0
		decay_mult: 0
	}
	param {
		lr_mult: 0
		decay_mult: 0
	}
	param {
		lr_mult: 0
		decay_mult: 0
	}
	batch_norm_param {
		use_global_stats: false
		moving_average_fraction: 0.95
	}
}
layer {
	name: "inception_conv_2_out32x1/scale"
	type: "Scale"
	bottom: "inception_conv_2_out32x1"
	top: "inception_conv_2_out32x1"
	param {
		lr_mult: 1.0
		decay_mult: 0.0
	}
	param {
		lr_mult: 2.0
		decay_mult: 0.0
	}
	scale_param {
		filler {
			value: 1
		}
		bias_term: true
		bias_filler {
			value: 0
		}
	}
}
layer {
	name: "inception_conv_2_out32x1/relu"
	type: "ReLU"
	bottom: "inception_conv_2_out32x1"
	top: "inception_conv_2_out32x1"
}
layer {
	name: "inception_conv_2_out32x3"
	type: "Convolution"
	bottom: "inception_conv_2_out32x1"
	top: "inception_conv_2_out32x3"
	param {
		lr_mult: 1
		decay_mult: 1
	}
	param {
		lr_mult: 2
		decay_mult: 1
	}
	convolution_param {
		num_output: 32
		kernel_size: 3
		stride: 1
		pad: 1
		weight_filler {
			type: "xavier"
		}
		bias_filler {
			type: "constant"
			value: 0
		}
	}
}
layer {
	name: "inception_conv_2_out32x3/bn"
	type: "BatchNorm"
	bottom: "inception_conv_2_out32x3"
	top: "inception_conv_2_out32x3"
	param {
		lr_mult: 0
		decay_mult: 0
	}
	param {
		lr_mult: 0
		decay_mult: 0
	}
	param {
		lr_mult: 0
		decay_mult: 0
	}
	batch_norm_param {
		use_global_stats: false
		moving_average_fraction: 0.95
	}
}
layer {
	name: "inception_conv_2_out32x3/scale"
	type: "Scale"
	bottom: "inception_conv_2_out32x3"
	top: "inception_conv_2_out32x3"
	param {
		lr_mult: 1.0
		decay_mult: 0.0
	}
	param {
		lr_mult: 2.0
		decay_mult: 0.0
	}
	scale_param {
		filler {
			value: 1
		}
		bias_term: true
		bias_filler {
			value: 0
		}
	}
}
layer {
	name: "inception_conv_2_out32x3/relu"
	type: "ReLU"
	bottom: "inception_conv_2_out32x3"
	top: "inception_conv_2_out32x3"
}
layer {
	name: "inception_conv_3_out32x1"
	type: "Convolution"
	bottom: "conv3_3x3_s1"  #################
	top: "inception_conv_3_out32x1"
	param {
		lr_mult: 1
		decay_mult: 1
	}
	param {
		lr_mult: 2
		decay_mult: 1
	}
	convolution_param {
		num_output: 32
		kernel_size: 1
		stride: 1
		weight_filler {
		    type: "xavier"
		}
		bias_filler {
		    type: "constant"
		    value: 0
		}
	}
}
layer {
	name: "inception_conv_3_out32x1/bn"
	type: "BatchNorm"
	bottom: "inception_conv_3_out32x1"
	top: "inception_conv_3_out32x1"
	param {
		lr_mult: 0
		decay_mult: 0
	}
	param {
		lr_mult: 0
		decay_mult: 0
	}
	param {
		lr_mult: 0
		decay_mult: 0
	}
	batch_norm_param {
		use_global_stats: false
		moving_average_fraction: 0.95
	}
}
layer {
	name: "inception_conv_3_out32x1/scale"
	type: "Scale"
	bottom: "inception_conv_3_out32x1"
	top: "inception_conv_3_out32x1"
	param {
		lr_mult: 1.0
		decay_mult: 0.0
	}
	param {
		lr_mult: 2.0
		decay_mult: 0.0
	}
	scale_param {
		filler {
			value: 1
		}
		bias_term: true
		bias_filler {
			value: 0
		}
	}
}
layer {
	name: "inception_conv_3_out32x1/relu"
	type: "ReLU"
	bottom: "inception_conv_3_out32x1"
	top: "inception_conv_3_out32x1"
}
layer {
	name: "inception_resnet_v2_a1_concat"
	type: "Concat"
	bottom: "inception_conv_1_out64x3"
	bottom: "inception_conv_2_out32x3"
	bottom: "inception_conv_3_out32x1"
	top: "inception_resnet_v2_a1_concat"
}
layer {
	name: "inception_resnet_v2_a1_up"
	type: "Convolution"
	bottom: "inception_resnet_v2_a1_concat"
	top: "inception_resnet_v2_a1_up"
	param {
		lr_mult: 1
		decay_mult: 1
	}
	param {
		lr_mult: 2
		decay_mult: 0
	}
	convolution_param {
		num_output: 64
		pad: 0
		kernel_size: 1
		stride: 1
		weight_filler {
			type: "xavier"
			std: 0.01
	}
	bias_filler {
		type: "constant"
		value: 0.0
	}
	}
}
layer {
	name: "inception_resnet_v2_a1_up_bn"
	type: "BatchNorm"
	bottom: "inception_resnet_v2_a1_up"
	top: "inception_resnet_v2_a1_up"
	param {
		lr_mult: 0.0
		decay_mult: 0.0
	}
	param {
		lr_mult: 0.0
		decay_mult: 0.0
	}
	param {
		lr_mult: 0.0
		decay_mult: 0.0
	}
	batch_norm_param {
		use_global_stats: false
		moving_average_fraction: 0.95
	}
}
layer {
	name: "inception_resnet_v2_a1_up_scale"
	type: "Scale"
	bottom: "inception_resnet_v2_a1_up"
	top: "inception_resnet_v2_a1_up"
	scale_param {
		bias_term: true
	}
}
layer {
	name: "inception_resnet_v2_a1_residual_eltwise"
	type: "Eltwise"
	bottom: "conv3_3x3_s1" #########
	bottom: "inception_resnet_v2_a1_up"
	top: "inception_resnet_v2_a1_residual_eltwise"
	eltwise_param {
		operation: SUM
	}
}

layer {
	name: "conv_stage_2_3x3_s2"
	type: "Convolution"
	bottom: "inception_resnet_v2_a1_residual_eltwise"
	top: "conv_stage_2_3x3_s2"
	param {
		lr_mult: 1
		decay_mult: 1
	}
	param {
		lr_mult: 2
		decay_mult: 0
	}
	convolution_param {
		num_output: 128
		pad: 0
		kernel_size: 3
		stride: 2
		weight_filler {
			type: "xavier"
			std: 0.01
		}
		bias_filler {
			type: "constant"
			value: 0.2
		}
	}
}
layer {
	name: "conv_stage_2_3x3_s2/bn"
	type: "BatchNorm"
	bottom: "conv_stage_2_3x3_s2"
	top: "conv_stage_2_3x3_s2"
	param {
		lr_mult: 0.0
		decay_mult: 0.0
	}
	param {
		lr_mult: 0.0
		decay_mult: 0.0
	}
	param {
		lr_mult: 0.0
		decay_mult: 0.0
	}
	batch_norm_param {
		use_global_stats: false
		moving_average_fraction: 0.95
	}
}
layer {
	name: "conv_stage_2_3x3_s2/scale"
	type: "Scale"
	bottom: "conv_stage_2_3x3_s2"
	top: "conv_stage_2_3x3_s2"
	scale_param {
		bias_term: true
	}
}
layer {
	name: "conv_stage_2_3x3_s2/relu"
	type: "ReLU"
	bottom: "conv_stage_2_3x3_s2"
	top: "conv_stage_2_3x3_s2"
}

layer {
	name: "stage_2_inception_conv_1_out64x1"
	type: "Convolution"
	bottom: "conv_stage_2_3x3_s2" #################
	top: "stage_2_inception_conv_1_out64x1"
	param {
		lr_mult: 1
		decay_mult: 1
	}
	param {
		lr_mult: 2
		decay_mult: 1
	}
	convolution_param {
		num_output: 64
		kernel_size: 1
		stride: 1
		weight_filler {
			type: "xavier"
		}
		bias_filler {
			type: "constant"
			value: 0
		}
	}
}
layer {
	name: "stage_2_inception_conv_1_out64x1/bn"
	type: "BatchNorm"
	bottom: "stage_2_inception_conv_1_out64x1"
	top: "stage_2_inception_conv_1_out64x1"
	param {
		lr_mult: 0
		decay_mult: 0
	}
	param {
		lr_mult: 0
		decay_mult: 0
	}
	param {
		lr_mult: 0
		decay_mult: 0
	}
	batch_norm_param {
		use_global_stats: false
		moving_average_fraction: 0.95
	}
}
layer {
	name: "stage_2_inception_conv_1_out64x1/scale"
	type: "Scale"
	bottom: "stage_2_inception_conv_1_out64x1"
	top: "stage_2_inception_conv_1_out64x1"
	param {
		lr_mult: 1.0
		decay_mult: 0.0
	}
	param {
		lr_mult: 2.0
		decay_mult: 0.0
	}
	scale_param {
		filler {
			value: 1
		}
		bias_term: true
		bias_filler {
			value: 0
		}
	}
}
layer {
	name: "stage_2_inception_conv_1_out64x1/relu"
	type: "ReLU"
	bottom: "stage_2_inception_conv_1_out64x1"
	top: "stage_2_inception_conv_1_out64x1"
}
layer {
	name: "stage_2_inception_conv_1_out128x3"
	type: "Convolution"
	bottom: "stage_2_inception_conv_1_out64x1"
	top: "stage_2_inception_conv_1_out128x3"
	param {
		lr_mult: 1
		decay_mult: 1
	}
	param {
		lr_mult: 2
		decay_mult: 1
	}
	convolution_param {
		num_output: 128
		kernel_size: 3
		stride: 1
		pad: 1
		weight_filler {
		    type: "xavier"
		}
		bias_filler {
		    type: "constant"
		    value: 0
		}
	}
}
layer {
	name: "stage_2_inception_conv_1_out128x3/bn"
	type: "BatchNorm"
	bottom: "stage_2_inception_conv_1_out128x3"
	top: "stage_2_inception_conv_1_out128x3"
	param {
		lr_mult: 0
		decay_mult: 0
	}
	param {
		lr_mult: 0
		decay_mult: 0
	}
	param {
		lr_mult: 0
		decay_mult: 0
	}
	batch_norm_param {
		use_global_stats: false
		moving_average_fraction: 0.95
	}
}
layer {
	name: "stage_2_inception_conv_1_out128x3/scale"
	type: "Scale"
	bottom: "stage_2_inception_conv_1_out128x3"
	top: "stage_2_inception_conv_1_out128x3"
	param {
		lr_mult: 1.0
		decay_mult: 0.0
	}
	param {
		lr_mult: 2.0
		decay_mult: 0.0
	}
	scale_param {
		filler {
			value: 1
		}
		bias_term: true
		bias_filler {
			value: 0
		}
	}
}
layer {
	name: "stage_2_inception_conv_1_out128x3/relu"
	type: "ReLU"
	bottom: "stage_2_inception_conv_1_out128x3"
	top: "stage_2_inception_conv_1_out128x3"
}
layer {
	name: "stage_2_inception_conv_1_out256x3"
	type: "Convolution"
	bottom: "stage_2_inception_conv_1_out128x3"
	top: "stage_2_inception_conv_1_out256x3"
	param {
		lr_mult: 1
		decay_mult: 1
	}
	param {
		lr_mult: 2
		decay_mult: 1
	}
	convolution_param {
		num_output: 256
		kernel_size: 3
		stride: 1
		pad: 1
		weight_filler {
		    type: "xavier"
		}
		bias_filler {
		    type: "constant"
		    value: 0
		}
	}
}
layer {
	name: "stage_2_inception_conv_1_out256x3/bn"
	type: "BatchNorm"
	bottom: "stage_2_inception_conv_1_out256x3"
	top: "stage_2_inception_conv_1_out256x3"
	param {
		lr_mult: 0
		decay_mult: 0
	}
	param {
		lr_mult: 0
		decay_mult: 0
	}
	param {
		lr_mult: 0
		decay_mult: 0
	}
	batch_norm_param {
		use_global_stats: false
		moving_average_fraction: 0.95
	}
}
layer {
	name: "stage_2_inception_conv_1_out256x3/scale"
	type: "Scale"
	bottom: "stage_2_inception_conv_1_out256x3"
	top: "stage_2_inception_conv_1_out256x3"
	param {
		lr_mult: 1.0
		decay_mult: 0.0
	}
	param {
		lr_mult: 2.0
		decay_mult: 0.0
	}
	scale_param {
		filler {
			value: 1
		}
		bias_term: true
		bias_filler {
			value: 0
		}
	}
}
layer {
	name: "stage_2_inception_conv_1_out256x3/relu"
	type: "ReLU"
	bottom: "stage_2_inception_conv_1_out256x3"
	top: "stage_2_inception_conv_1_out256x3"
}
layer {
	name: "stage_2_inception_conv_2_out64x1"
	type: "Convolution"
	bottom: "conv_stage_2_3x3_s2"  #################
	top: "stage_2_inception_conv_2_out64x1"
	param {
		lr_mult: 1
		decay_mult: 1
	}
	param {
		lr_mult: 2
		decay_mult: 1
	}
	convolution_param {
		num_output: 64
		kernel_size: 1
		stride: 1
		weight_filler {
		    type: "xavier"
		}
		bias_filler {
		    type: "constant"
		    value: 0
		}
	}
}
layer {
	name: "stage_2_inception_conv_2_out64x1/bn"
	type: "BatchNorm"
	bottom: "stage_2_inception_conv_2_out64x1"
	top: "stage_2_inception_conv_2_out64x1"
	param {
		lr_mult: 0
		decay_mult: 0
	}
	param {
		lr_mult: 0
		decay_mult: 0
	}
	param {
		lr_mult: 0
		decay_mult: 0
	}
	batch_norm_param {
		use_global_stats: false
		moving_average_fraction: 0.95
	}
}
layer {
	name: "stage_2_inception_conv_2_out64x1/scale"
	type: "Scale"
	bottom: "stage_2_inception_conv_2_out64x1"
	top: "stage_2_inception_conv_2_out64x1"
	param {
		lr_mult: 1.0
		decay_mult: 0.0
	}
	param {
		lr_mult: 2.0
		decay_mult: 0.0
	}
	scale_param {
		filler {
			value: 1
		}
		bias_term: true
		bias_filler {
			value: 0
		}
	}
}
layer {
	name: "stage_2_inception_conv_2_out64x1/relu"
	type: "ReLU"
	bottom: "stage_2_inception_conv_2_out64x1"
	top: "stage_2_inception_conv_2_out64x1"
}
layer {
	name: "stage_2_inception_conv_2_out128x3"
	type: "Convolution"
	bottom: "stage_2_inception_conv_2_out64x1"
	top: "stage_2_inception_conv_2_out128x3"
	param {
		lr_mult: 1
		decay_mult: 1
	}
	param {
		lr_mult: 2
		decay_mult: 1
	}
	convolution_param {
		num_output: 128
		kernel_size: 3
		stride: 1
		pad: 1
		weight_filler {
			type: "xavier"
		}
		bias_filler {
			type: "constant"
			value: 0
		}
	}
}
layer {
	name: "stage_2_inception_conv_2_out128x3/bn"
	type: "BatchNorm"
	bottom: "stage_2_inception_conv_2_out128x3"
	top: "stage_2_inception_conv_2_out128x3"
	param {
		lr_mult: 0
		decay_mult: 0
	}
	param {
		lr_mult: 0
		decay_mult: 0
	}
	param {
		lr_mult: 0
		decay_mult: 0
	}
	batch_norm_param {
		use_global_stats: false
		moving_average_fraction: 0.95
	}
}
layer {
	name: "stage_2_inception_conv_2_out128x3/scale"
	type: "Scale"
	bottom: "stage_2_inception_conv_2_out128x3"
	top: "stage_2_inception_conv_2_out128x3"
	param {
		lr_mult: 1.0
		decay_mult: 0.0
	}
	param {
		lr_mult: 2.0
		decay_mult: 0.0
	}
	scale_param {
		filler {
			value: 1
		}
		bias_term: true
		bias_filler {
			value: 0
		}
	}
}
layer {
	name: "stage_2_inception_conv_2_out128x3/relu"
	type: "ReLU"
	bottom: "stage_2_inception_conv_2_out128x3"
	top: "stage_2_inception_conv_2_out128x3"
}
layer {
	name: "stage_2_inception_conv_3_out128x1"
	type: "Convolution"
	bottom: "conv_stage_2_3x3_s2"  #################
	top: "stage_2_inception_conv_3_out128x1"
	param {
		lr_mult: 1
		decay_mult: 1
	}
	param {
		lr_mult: 2
		decay_mult: 1
	}
	convolution_param {
		num_output: 128
		kernel_size: 1
		stride: 1
		weight_filler {
			type: "xavier"
		}
		bias_filler {
			type: "constant"
			value: 0
		}
	}
}
layer {
	name: "stage_2_inception_conv_3_out128x1/bn"
	type: "BatchNorm"
	bottom: "stage_2_inception_conv_3_out128x1"
	top: "stage_2_inception_conv_3_out128x1"
	param {
		lr_mult: 0
		decay_mult: 0
	}
	param {
		lr_mult: 0
		decay_mult: 0
	}
	param {
		lr_mult: 0
		decay_mult: 0
	}
	batch_norm_param {
		use_global_stats: false
		moving_average_fraction: 0.95
	}
}
layer {
	name: "stage_2_inception_conv_3_out128x1/scale"
	type: "Scale"
	bottom: "stage_2_inception_conv_3_out128x1"
	top: "stage_2_inception_conv_3_out128x1"
	param {
		lr_mult: 1.0
		decay_mult: 0.0
	}
	param {
		lr_mult: 2.0
		decay_mult: 0.0
	}
	scale_param {
		filler {
			value: 1
		}
		bias_term: true
		bias_filler {
			value: 0
		}
	}
}
layer {
	name: "stage_2_inception_conv_3_out128x1/relu"
	type: "ReLU"
	bottom: "stage_2_inception_conv_3_out128x1"
	top: "stage_2_inception_conv_3_out128x1"
}
layer {
	name: "stage_2_inception_resnet_v2_a1_concat"
	type: "Concat"
	bottom: "stage_2_inception_conv_1_out256x3"
	bottom: "stage_2_inception_conv_2_out128x3"
	bottom: "stage_2_inception_conv_3_out128x1"
	top: "stage_2_inception_resnet_v2_a1_concat"
}
layer {
	name: "stage_2_conv_stage_2_3x3_s2_up"
	type: "Convolution"
	bottom: "conv_stage_2_3x3_s2"
	top: "stage_2_conv_stage_2_3x3_s2_up"
	param {
		lr_mult: 1
		decay_mult: 1
	}
	param {
		lr_mult: 2
		decay_mult: 0
	}
	convolution_param {
		num_output: 512
		pad: 0
		kernel_size: 1
		stride: 1
		weight_filler {
			type: "xavier"
			std: 0.01
	}
	bias_filler {
		type: "constant"
		value: 0.0
	}
	}
}
layer {
	name: "stage_2_conv_stage_2_3x3_s2_up"
	type: "BatchNorm"
	bottom: "stage_2_conv_stage_2_3x3_s2_up"
	top: "stage_2_conv_stage_2_3x3_s2_up"
	param {
		lr_mult: 0.0
		decay_mult: 0.0
	}
	param {
		lr_mult: 0.0
		decay_mult: 0.0
	}
	param {
		lr_mult: 0.0
		decay_mult: 0.0
	}
	batch_norm_param {
		use_global_stats: false
		moving_average_fraction: 0.95
	}
}
layer {
	name: "stage_2_conv_stage_2_3x3_s2_up"
	type: "Scale"
	bottom: "stage_2_conv_stage_2_3x3_s2_up"
	top: "stage_2_conv_stage_2_3x3_s2_up"
	scale_param {
		bias_term: true
	}
}
layer {
	name: "stage_2_inception_resnet_v2_a1_residual_eltwise"
	type: "Eltwise"
	bottom: "stage_2_conv_stage_2_3x3_s2_up" #########
	bottom: "stage_2_inception_resnet_v2_a1_concat"
	top: "stage_2_inception_resnet_v2_a1_residual_eltwise"
	eltwise_param {
		operation: SUM
	}
}

layer {
	name: "conv_stage_3_3x3_s2"
	type: "Convolution"
	bottom: "stage_2_inception_resnet_v2_a1_residual_eltwise"
	top: "conv_stage_3_3x3_s2"
	param {
		lr_mult: 1
		decay_mult: 1
	}
	param {
		lr_mult: 2
		decay_mult: 0
	}
	convolution_param {
		num_output: 1024
		pad: 0
		kernel_size: 3
		stride: 2
		weight_filler {
			type: "xavier"
			std: 0.01
		}
		bias_filler {
			type: "constant"
			value: 0.2
		}
	}
}
layer {
	name: "conv_stage_3_3x3_s2/bn"
	type: "BatchNorm"
	bottom: "conv_stage_3_3x3_s2"
	top: "conv_stage_3_3x3_s2"
	param {
		lr_mult: 0.0
		decay_mult: 0.0
	}
	param {
		lr_mult: 0.0
		decay_mult: 0.0
	}
	param {
		lr_mult: 0.0
		decay_mult: 0.0
	}
	batch_norm_param {
		use_global_stats: false
		moving_average_fraction: 0.95
	}
}
layer {
	name: "conv_stage_3_3x3_s2/scale"
	type: "Scale"
	bottom: "conv_stage_3_3x3_s2"
	top: "conv_stage_3_3x3_s2"
	scale_param {
		bias_term: true
	}
}
layer {
	name: "conv_stage_3_3x3_s2/relu"
	type: "ReLU"
	bottom: "conv_stage_3_3x3_s2"
	top: "conv_stage_3_3x3_s2"
}
layer {
	name: "conv_stage_3_1x1_s1"
	type: "Convolution"
	bottom: "conv_stage_3_3x3_s2"
	top: "conv_stage_3_1x1_s1"
	param {
		lr_mult: 1
		decay_mult: 1
	}
	param {
		lr_mult: 2
		decay_mult: 0
	}
	convolution_param {
		num_output: 1024
		pad: 0
		kernel_size: 1
		stride: 1
		weight_filler {
			type: "xavier"
			std: 0.01
		}
		bias_filler {
			type: "constant"
			value: 0.2
		}
	}
}
layer {
	name: "conv_stage_3_1x1_s1/bn"
	type: "BatchNorm"
	bottom: "conv_stage_3_1x1_s1"
	top: "conv_stage_3_1x1_s1"
	param {
		lr_mult: 0.0
		decay_mult: 0.0
	}
	param {
		lr_mult: 0.0
		decay_mult: 0.0
	}
	param {
		lr_mult: 0.0
		decay_mult: 0.0
	}
	batch_norm_param {
		use_global_stats: false
		moving_average_fraction: 0.95
	}
}
layer {
	name: "conv_stage_3_1x1_s1/scale"
	type: "Scale"
	bottom: "conv_stage_3_1x1_s1"
	top: "conv_stage_3_1x1_s1"
	scale_param {
		bias_term: true
	}
}
layer {
	name: "conv_stage_3_1x1_s1/relu"
	type: "ReLU"
	bottom: "conv_stage_3_1x1_s1"
	top: "conv_stage_3_1x1_s1"
}

layer {
	name: "conv_stage_4_3x3_s2"
	type: "Convolution"
	bottom: "conv_stage_3_1x1_s1"
	top: "conv_stage_4_3x3_s2"
	param {
		lr_mult: 1
		decay_mult: 1
	}
	param {
		lr_mult: 2
		decay_mult: 0
	}
	convolution_param {
		num_output: 512
		pad: 0
		kernel_size: 3
		stride: 2
		weight_filler {
			type: "xavier"
			std: 0.01
		}
		bias_filler {
			type: "constant"
			value: 0.2
		}
	}
}
layer {
	name: "conv_stage_4_3x3_s2/bn"
	type: "BatchNorm"
	bottom: "conv_stage_4_3x3_s2"
	top: "conv_stage_4_3x3_s2"
	param {
		lr_mult: 0.0
		decay_mult: 0.0
	}
	param {
		lr_mult: 0.0
		decay_mult: 0.0
	}
	param {
		lr_mult: 0.0
		decay_mult: 0.0
	}
	batch_norm_param {
		use_global_stats: false
		moving_average_fraction: 0.95
	}
}
layer {
	name: "conv_stage_4_3x3_s2/scale"
	type: "Scale"
	bottom: "conv_stage_4_3x3_s2"
	top: "conv_stage_4_3x3_s2"
	scale_param {
		bias_term: true
	}
}
layer {
	name: "conv_stage_4_3x3_s2/relu"
	type: "ReLU"
	bottom: "conv_stage_4_3x3_s2"
	top: "conv_stage_4_3x3_s2"
}
##############################
layer {
	name: "conv_stage_4_1x1_s1"
	type: "Convolution"
	bottom: "conv_stage_4_3x3_s2"
	top: "conv_stage_4_1x1_s1"
	param {
		lr_mult: 1
		decay_mult: 1
	}
	param {
		lr_mult: 2
		decay_mult: 0
	}
	convolution_param {
		num_output: 512
		pad: 0
		kernel_size: 3
		stride: 1
		weight_filler {
			type: "xavier"
			std: 0.01
		}
		bias_filler {
			type: "constant"
			value: 0.2
		}
	}
}
layer {
	name: "conv_stage_4_1x1_s1/bn"
	type: "BatchNorm"
	bottom: "conv_stage_4_1x1_s1"
	top: "conv_stage_4_1x1_s1"
	param {
		lr_mult: 0.0
		decay_mult: 0.0
	}
	param {
		lr_mult: 0.0
		decay_mult: 0.0
	}
	param {
		lr_mult: 0.0
		decay_mult: 0.0
	}
	batch_norm_param {
		use_global_stats: false
		moving_average_fraction: 0.95
	}
}
layer {
	name: "conv_stage_4_1x1_s1/scale"
	type: "Scale"
	bottom: "conv_stage_4_1x1_s1"
	top: "conv_stage_4_1x1_s1"
	scale_param {
		bias_term: true
	}
}
layer {
	name: "conv_stage_4_1x1_s1/relu"
	type: "ReLU"
	bottom: "conv_stage_4_1x1_s1"
	top: "conv_stage_4_1x1_s1"
}
###############################

layer {
	name: "conv_stage_5_3x3_s1"
	type: "Convolution"
	bottom: "conv_stage_4_1x1_s1"
	top: "conv_stage_5_3x3_s1"
	param {
		lr_mult: 1
		decay_mult: 1
	}
	param {
		lr_mult: 2
		decay_mult: 0
	}
	convolution_param {
		num_output: 256
		pad: 0
		kernel_size: 3
		stride: 1
		weight_filler {
			type: "xavier"
			std: 0.01
		}
		bias_filler {
			type: "constant"
			value: 0.2
		}
	}
}
layer {
	name: "conv_stage_5_3x3_s1/bn"
	type: "BatchNorm"
	bottom: "conv_stage_5_3x3_s1"
	top: "conv_stage_5_3x3_s1"
	param {
		lr_mult: 0.0
		decay_mult: 0.0
	}
	param {
		lr_mult: 0.0
		decay_mult: 0.0
	}
	param {
		lr_mult: 0.0
		decay_mult: 0.0
	}
	batch_norm_param {
		use_global_stats: false
		moving_average_fraction: 0.95
	}
}
layer {
	name: "conv_stage_5_3x3_s1/scale"
	type: "Scale"
	bottom: "conv_stage_5_3x3_s1"
	top: "conv_stage_5_3x3_s1"
	scale_param {
		bias_term: true
	}
}
layer {
	name: "conv_stage_5_3x3_s1/relu"
	type: "ReLU"
	bottom: "conv_stage_5_3x3_s1"
	top: "conv_stage_5_3x3_s1"
}

layer {
	name: "conv6_faceangle"
	type: "InnerProduct"
	bottom: "conv_stage_5_3x3_s1"
	top: "conv6_faceangle"
	param {
		lr_mult: 1
		decay_mult: 1
	}
	param {
		lr_mult: 2
		decay_mult: 1
	}
	inner_product_param {
		#kernel_size: 1
		num_output: 5
		weight_filler {
			type: "xavier"
		}
		bias_filler {
			type: "constant"
			value: 0
		}
	}
}

layer {
	name: "conv6_facecontour"
	type: "InnerProduct"
	bottom: "conv_stage_5_3x3_s1"
	top: "conv6_facecontour"
	param {
		lr_mult: 1
		decay_mult: 1
	}
	param {
		lr_mult: 2
		decay_mult: 1
	}
	inner_product_param {
		#kernel_size: 1
		num_output: 42
		weight_filler {
			type: "xavier"
		}
		bias_filler {
			type: "constant"
			value: 0
		}
	}
}
layer {
	name: "conv6_facecontour/bn"
	type: "BatchNorm"
	bottom: "conv6_facecontour"
	top: "conv6_facecontour"
	param {
		lr_mult: 0.0
		decay_mult: 0.0
	}
	param {
		lr_mult: 0.0
		decay_mult: 0.0
	}
	param {
		lr_mult: 0.0
		decay_mult: 0.0
	}
	batch_norm_param {
		use_global_stats: false
		moving_average_fraction: 0.95
	}
}
layer {
	name: "conv6_facecontour/scale"
	type: "Scale"
	bottom: "conv6_facecontour"
	top: "conv6_facecontour"
	scale_param {
		bias_term: true
	}
}
layer {
	name: "conv6_facecontour/relu"
	type: "ReLU"
	bottom: "conv6_facecontour"
	top: "conv6_facecontour"
}

layer {
	name: "multiface_loss"
	type: "MultiFacePoseLoss"
	bottom: "conv6_facecontour"
	bottom: "conv6_faceangle"
	bottom: "label"
	top: "multiface_loss"
	loss_weight: 0.5
	include {
		phase: TRAIN
	}
	propagate_down: true
	propagate_down: true
	propagate_down: false
	loss_param {
		normalization: VALID
	}
	multiface_pose_loss_param{
		regs_face_contour_loss_type : SMOOTH_L1
		regs_face_pose_loss_type: SMOOTH_L1
		pose_weights: 1.0
	}
}
